#include <iostream>
#include <math.h>
#include <numeric>
#include <vector>
#include <assert.h>
#include "cuda_utils.hpp"

#define BLOCK_SZ 256


__global__ void naive_add(float *input, float output, int N){
    int idx = blockDim.x * blockIdx.x + threadIdx.x;
    
    if(idx < N)
        printf("Generated by thread %d , %f + %f = %f(New Output)",
                                    idx,input,output,atomicAdd(output,input[idx]));
}


int main(){
    // get sizes properly
    const int N = 1 << 20;  // 1M elements
    const size_t bytes = N * sizeof(float);

    // give proper C++ STL containers for CUDA work
    std::vector<float> h_a(N);

    // either populate them or get input from them
    // always pass flat contigous arrays to CUDA Kernels
    for (int i = 0; i < N; ++i) {
        if(i % 2 == 0)
            h_a[i] = 1.0f;
        else
            h_a[i] = 2.0f;
    }

    // ground truth ,test later 
    float sum_truth = std::accumulate(h_a.begin(),h_a.end(),0);

    // device variables
    float *d_input, d_output;
    
    // Allocate memory on device
    CUDA_CHECK(cudaMalloc(d_input,bytes));
    CUDA_CHECK(cudaMalloc(d_input,bytes));

    // copy host variable's data to appropriate device variables or use cudaMemSet for this
    CUDA_CHECK(cudaMemcpy(d_input,h_input.data(),bytes,cudaMemcpyHostToDevice));

    // memset output to a particular default value
    CUDA_CHECK(cudaMemset(d_output,0.0f,bytes));

    dim3 blockSize = BLOCK_SZ;
    dim3 gridSize = (N + blockSize  - 1) / blockSize;

    naive_add<<<gridSize,blockSize>>>(d_input,d_output,N);


    assert(d_output == sum_truth);
    std::cout << "The output is" << d_output;
    cudaFree(d_input);
    cudaFree(d_output);

    return 0;
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a74495ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Colab GPU available:\", torch.cuda.is_available())\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c503bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 28 05:16:22 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c5c53e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMakelists.txt\tmatrix_multiplication  test_colab_server.ipynb\n",
      "include\t\tREADME.md\t       vector_add\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40c22393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmake version 3.31.10\n",
      "\n",
      "CMake suite maintained and supported by Kitware (kitware.com/cmake).\n"
     ]
    }
   ],
   "source": [
    "!cmake --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ed1ef",
   "metadata": {},
   "source": [
    "# Run from here always after any change in git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5b2d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca45e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631aa11b",
   "metadata": {},
   "source": [
    "# Make a new clone from the git repo and then run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38e856e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'GPU_mode'...\n",
      "remote: Enumerating objects: 38, done.\u001b[K\n",
      "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 38 (delta 15), reused 32 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (38/38), 7.90 KiB | 7.90 MiB/s, done.\n",
      "Resolving deltas: 100% (15/15), done.\n",
      "/content/GPU_mode\n",
      "CMakeLists.txt\tmatrix_multiplication  test_colab_server.ipynb\n",
      "include\t\tREADME.md\t       vector_add\n"
     ]
    }
   ],
   "source": [
    "# Always start from /content\n",
    "%cd /content\n",
    "\n",
    "# Remove any old copies so paths don't get nested\n",
    "!rm -rf GPU_mode\n",
    "\n",
    "# Clone your repo (note the exact repo name in the URL)\n",
    "!git clone https://github.com/parthshinde1221/GPU_mode.git\n",
    "\n",
    "# Enter the repo root\n",
    "%cd GPU_mode\n",
    "\n",
    "# Sanity check: you MUST see CMakeLists.txt here\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f875e",
   "metadata": {},
   "source": [
    "# Building all CUDA kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfcc1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The CXX compiler identification is GNU 11.4.0\n",
      "-- The CUDA compiler identification is NVIDIA 12.5.82 with host compiler GNU 11.4.0\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Detecting CUDA compiler ABI info\n",
      "-- Detecting CUDA compiler ABI info - done\n",
      "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
      "-- Detecting CUDA compile features\n",
      "-- Detecting CUDA compile features - done\n",
      "-- Configuring done (2.3s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /content/GPU_mode/build\n",
      "[ 33%] \u001b[32mBuilding CUDA object matrix_multiplication/CMakeFiles/matmul.dir/matmul.cu.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CUDA object vector_add/CMakeFiles/vec_add.dir/vec_add.cu.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/vec_add.dir/cmake_device_link.o\u001b[0m\n",
      "[ 66%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/matmul.dir/cmake_device_link.o\u001b[0m\n",
      "[ 83%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/matmul\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/vec_add\u001b[0m\n",
      "[100%] Built target matmul\n",
      "[100%] Built target vec_add\n"
     ]
    }
   ],
   "source": [
    "# Configure the project (top-level CMakeLists.txt)\n",
    "!cmake -S . -B build -DCMAKE_BUILD_TYPE=Release\n",
    "\n",
    "# Build all targets (matmul, vec_add, etc.)\n",
    "!cmake --build build -j 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe34d054",
   "metadata": {},
   "source": [
    "# Optional build single kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernels = [\"matmul\", \"vec_add\"]  # target names from each CMakeLists.txt\n",
    "\n",
    "# for k in kernels:\n",
    "#     print(f\"\\n=== Building {k} ===\")\n",
    "#     !cmake --build build --target {k} -j 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1df4574",
   "metadata": {},
   "source": [
    "# Running all Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424f05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running matmul ===\n",
      "C[0] = 1024 (expected 1024)\n",
      "\n",
      "=== Running vec_add ===\n",
      "c[0] = 3 (expected 3)\n",
      "c[N-1] = 3 (expected 3)\n"
     ]
    }
   ],
   "source": [
    "kernels = [\"matmul_naive\", \"vec_add_naive\",\"matmul_tiled\",\"vec_add_opt\"]  # add more later: \"softmax\", \"conv\", etc.\n",
    "\n",
    "for k in kernels:\n",
    "    print(f\"\\n=== Running {k} ===\")\n",
    "    !./build/bin/{k}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b565db",
   "metadata": {},
   "source": [
    "# CUDA MemCheck all kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a30afd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2aa92b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\tinclude\t\t       profiles   test_colab_server.ipynb\n",
      "CMakeLists.txt\tmatrix_multiplication  README.md  vector_add\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2022c2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== cuda-memcheck matmul ===\n",
      "Saved profiles/matmul_memcheck.txt\n",
      "\n",
      "=== cuda-memcheck vec_add ===\n",
      "Saved profiles/vec_add_memcheck.txt\n"
     ]
    }
   ],
   "source": [
    "kernels = [\"matmul_naive\", \"vec_add_naive\",\"matmul_tiled\",\"vec_add_opt\"]\n",
    "\n",
    "for k in kernels:\n",
    "    print(f\"\\n=== cuda-memcheck {k} ===\")\n",
    "    !cuda-memcheck --leak-check full ./build/bin/{k} > profiles/{k}_memcheck.txt 2>&1\n",
    "    print(f\"Saved profiles/{k}_memcheck.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a3ad80",
   "metadata": {},
   "source": [
    "# NCU Profile each kernel all kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c77d5334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\tinclude\t\t       profiles   test_colab_server.ipynb\n",
      "CMakeLists.txt\tmatrix_multiplication  README.md  vector_add\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9463e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin\t\tCMakeFiles\t     Makefile\t\t    vector_add\n",
      "CMakeCache.txt\tcmake_install.cmake  matrix_multiplication\n"
     ]
    }
   ],
   "source": [
    "!ls build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae20b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul\tvec_add\n"
     ]
    }
   ],
   "source": [
    "!ls build/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e34171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==ERROR== 'build/bin/.' does not exist or is not an executable. Please make sure to specify the absolute path to 'build/bin/.' if the executable is not in the local directory.\n"
     ]
    }
   ],
   "source": [
    "!ncu build/bin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c1a1c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\tinclude\t\t       profiles   test_colab_server.ipynb\n",
      "CMakeLists.txt\tmatrix_multiplication  README.md  vector_add\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bcb975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import IFrame\n",
    "# import os\n",
    "\n",
    "# os.makedirs(\"profiles\", exist_ok=True)\n",
    "\n",
    "# kernels = [\"matmul\", \"vec_add\"]\n",
    "\n",
    "# for k in kernels:\n",
    "#     print(f\"\\n=== Profiling {k} with ncu ===\")\n",
    "#     # NCU_DEFAULTS=\"\" clears any default --export that Colab may set\n",
    "#     !NCU_DEFAULTS=\"\" ncu -f --set full --export html -o profiles/{k} ./build/bin/{k}\n",
    "#     display(IFrame(f\"profiles/{k}.html\", width=1024, height=600))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12bad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running Nsight Compute and saving reports ===\n",
      "\n",
      "[1] Profiling matmul with ncu ...\n",
      "==PROF== Connected to process 44603 (/content/GPU_mode/build/bin/matmul)\n",
      "==PROF== Profiling \"matmul_kernel\" - 0: 0%....50%....100% - 30 passes\n",
      "C[0] = 1024 (expected 1024)\n",
      "==PROF== Disconnected from process 44603\n",
      "==PROF== Report: /content/GPU_mode/profiles/matmul.ncu-rep\n",
      "--> Saved report: profiles/matmul.ncu-rep\n",
      "--> Duration for matmul:\n",
      "    Duration                         ms         1.15\n",
      "\n",
      "[1] Profiling vec_add with ncu ...\n",
      "==PROF== Connected to process 44700 (/content/GPU_mode/build/bin/vec_add)\n",
      "==PROF== Profiling \"vec_add_kernel\" - 0: 0%....50%....100% - 30 passes\n",
      "c[0] = 3 (expected 3)\n",
      "c[N-1] = 3 (expected 3)\n",
      "==PROF== Disconnected from process 44700\n",
      "==PROF== Report: /content/GPU_mode/profiles/vec_add.ncu-rep\n",
      "--> Saved report: profiles/vec_add.ncu-rep\n",
      "--> Duration for vec_add:\n",
      "    Duration                         us        49.95\n",
      "\n",
      "All reports saved:\n",
      "total 464K\n",
      "-rw-r--r-- 1 root root   52 Nov 28 05:46 matmul_memcheck.txt\n",
      "-rw-r--r-- 1 root root 268K Nov 28 06:10 matmul.ncu-rep\n",
      "-rw-r--r-- 1 root root   52 Nov 28 05:46 vec_add_memcheck.txt\n",
      "-rw-r--r-- 1 root root 187K Nov 28 06:10 vec_add.ncu-rep\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"profiles\", exist_ok=True)\n",
    "\n",
    "kernels = [\"matmul_naive\", \"vec_add_naive\",\"matmul_tiled\",\"vec_add_opt\"]\n",
    "\n",
    "# -------- First loop: run profiling & save reports --------\n",
    "print(\"=== Running Nsight Compute and saving reports ===\")\n",
    "for k in kernels:\n",
    "    print(f\"\\n[1] Profiling {k} with ncu ...\")\n",
    "    !NCU_DEFAULTS=\"\" ncu -f --set full -o profiles/{k} ./build/bin/{k}\n",
    "    print(f\"--> Saved report: profiles/{k}.ncu-rep\")\n",
    "    \n",
    "    # Print the kernel Duration from the report\n",
    "    print(f\"--> Duration for {k}:\")\n",
    "    !NCU_DEFAULTS=\"\" ncu --import profiles/{k}.ncu-rep --page details | grep \"Duration\"\n",
    "\n",
    "print(\"\\nAll reports saved:\")\n",
    "!ls -lh profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "65407218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Printing Nsight Compute details for each kernel ===\n",
      "\n",
      "[2] Nsight Compute details page for matmul\n",
      "[40910] matmul@127.0.0.1\n",
      "  matmul_kernel(const float *, const float *, float *, int) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ----------- ------------\n",
      "    Metric Name             Metric Unit Metric Value\n",
      "    ----------------------- ----------- ------------\n",
      "    DRAM Frequency                  Ghz         5.00\n",
      "    SM Frequency                    Mhz       584.97\n",
      "    Elapsed Cycles                cycle      672,698\n",
      "    Memory Throughput                 %        62.40\n",
      "    DRAM Throughput                   %         1.26\n",
      "    Duration                         ms         1.15\n",
      "    L1/TEX Cache Throughput           %        93.62\n",
      "    L2 Cache Throughput               %         6.75\n",
      "    SM Active Cycles              cycle   660,623.18\n",
      "    Compute (SM) Throughput           %        62.40\n",
      "    ----------------------- ----------- ------------\n",
      "\n",
      "    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. \n",
      "          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               \n",
      "\n",
      "    Section: GPU Speed Of Light Roofline Chart\n",
      "    INF   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 8% of \n",
      "          this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide       \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline      \n",
      "          analysis.                                                                                                     \n",
      "\n",
      "    Section: PM Sampling\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Maximum Buffer Size             Mbyte         2.49\n",
      "    Dropped Samples                sample            0\n",
      "    Maximum Sampling Interval       cycle       80,000\n",
      "    # Pass Groups                                    1\n",
      "    ------------------------- ----------- ------------\n",
      "\n",
      "    Section: Compute Workload Analysis\n",
      "    -------------------- ----------- ------------\n",
      "    Metric Name          Metric Unit Metric Value\n",
      "    -------------------- ----------- ------------\n",
      "    Executed Ipc Active   inst/cycle         0.74\n",
      "    Executed Ipc Elapsed  inst/cycle         0.72\n",
      "    Issue Slots Busy               %        18.45\n",
      "    Issued Ipc Active     inst/cycle         0.74\n",
      "    SM Busy                        %        21.27\n",
      "    -------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 83.49%                                                                                    \n",
      "          All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps   \n",
      "          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             \n",
      "\n",
      "    Section: Memory Workload Analysis\n",
      "    ----------------- ----------- ------------\n",
      "    Metric Name       Metric Unit Metric Value\n",
      "    ----------------- ----------- ------------\n",
      "    Memory Throughput     Gbyte/s         4.04\n",
      "    Mem Busy                    %        46.81\n",
      "    Max Bandwidth               %        62.40\n",
      "    L1/TEX Hit Rate             %        87.37\n",
      "    L2 Hit Rate                 %        97.70\n",
      "    Mem Pipes Busy              %        62.40\n",
      "    ----------------- ----------- ------------\n",
      "\n",
      "    Section: Memory Workload Analysis Chart\n",
      "    WRN   The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an  \n",
      "          additional metric could enable the rule to provide more guidance.                                             \n",
      "\n",
      "    Section: Memory Workload Analysis Tables\n",
      "    OPT   Est. Speedup: 40.96%                                                                                          \n",
      "          The memory access pattern for global loads from L1TEX might not be optimal. On average, only 18.0 of the 32   \n",
      "          bytes transmitted per sector are utilized by each thread. This could possibly be caused by a stride between   \n",
      "          threads. Check the Source Counters section for uncoalesced global loads.                                      \n",
      "\n",
      "    Section: Scheduler Statistics\n",
      "    ---------------------------- ----------- ------------\n",
      "    Metric Name                  Metric Unit Metric Value\n",
      "    ---------------------------- ----------- ------------\n",
      "    One or More Eligible                   %        18.44\n",
      "    Issued Warp Per Scheduler                        0.18\n",
      "    No Eligible                            %        81.56\n",
      "    Active Warps Per Scheduler          warp         7.58\n",
      "    Eligible Warps Per Scheduler        warp         0.72\n",
      "    ---------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 37.6%                                                                                     \n",
      "          Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      \n",
      "          issues an instruction every 5.4 cycles. This might leave hardware resources underutilized and may lead to     \n",
      "          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    \n",
      "          7.58 active warps per scheduler, but only an average of 0.72 warps were eligible per cycle. Eligible warps    \n",
      "          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   \n",
      "          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      \n",
      "          eligible warps, avoid possible load imbalances due to highly different execution durations per warp.          \n",
      "          Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.            \n",
      "\n",
      "    Section: Warp State Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Warp Cycles Per Issued Instruction             cycle        41.11\n",
      "    Warp Cycles Per Executed Instruction           cycle        41.12\n",
      "    Avg. Active Threads Per Warp                                   32\n",
      "    Avg. Not Predicated Off Threads Per Warp                    31.92\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 37.6%                                                                                           \n",
      "          On average, each warp of this kernel spends 33.2 cycles being stalled waiting for the L1 instruction queue    \n",
      "          for local and global (LG) memory operations to be not full. Typically, this stall occurs only when executing  \n",
      "          local or global memory instructions extremely frequently. Avoid redundant global memory accesses. Try to      \n",
      "          avoid using thread-local memory by checking if dynamically indexed arrays are declared in local scope, of if  \n",
      "          the kernel has excessive register pressure causing by spills. If applicable, consider combining multiple      \n",
      "          lower-width memory operations into fewer wider memory operations and try interleaving memory operations and   \n",
      "          math instructions. This stall type represents about 80.8% of the total average of 41.1 cycles between         \n",
      "          issuing two instructions.                                                                                     \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    INF   Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on         \n",
      "          sampling data. The Kernel Profiling Guide                                                                     \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details    \n",
      "          on each stall reason.                                                                                         \n",
      "\n",
      "    Section: Instruction Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Avg. Executed Instructions Per Scheduler        inst      121,856\n",
      "    Executed Instructions                           inst   19,496,960\n",
      "    Avg. Issued Instructions Per Scheduler          inst   121,881.03\n",
      "    Issued Instructions                             inst   19,500,965\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   256\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  1,024\n",
      "    Registers Per Thread             register/thread              49\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM              40\n",
      "    Threads                                   thread         262,144\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                6.40\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            4\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            4\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        94.77\n",
      "    Achieved Active Warps Per SM           warp        30.33\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle    72,526.50\n",
      "    Total DRAM Elapsed Cycles        cycle   46,039,040\n",
      "    Average L1 Active Cycles         cycle   660,623.18\n",
      "    Total L1 Elapsed Cycles          cycle   26,964,296\n",
      "    Average L2 Active Cycles         cycle   794,100.66\n",
      "    Total L2 Elapsed Cycles          cycle   31,461,024\n",
      "    Average SM Active Cycles         cycle   660,623.18\n",
      "    Total SM Elapsed Cycles          cycle   26,964,296\n",
      "    Average SMSP Active Cycles       cycle   661,000.55\n",
      "    Total SMSP Elapsed Cycles        cycle  107,857,184\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    Section: Source Counters\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Branch Instructions Ratio           %         0.02\n",
      "    Branch Instructions              inst      335,872\n",
      "    Branch Efficiency                   %          100\n",
      "    Avg. Divergent Branches                          0\n",
      "    ------------------------- ----------- ------------\n",
      "\n",
      "\n",
      "[2] Nsight Compute details page for vec_add\n",
      "[40986] vec_add@127.0.0.1\n",
      "  vec_add_kernel(const float *, const float *, float *, int) (4096, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ----------- ------------\n",
      "    Metric Name             Metric Unit Metric Value\n",
      "    ----------------------- ----------- ------------\n",
      "    DRAM Frequency                  Ghz         4.62\n",
      "    SM Frequency                    Mhz       584.54\n",
      "    Elapsed Cycles                cycle       29,113\n",
      "    Memory Throughput                 %        89.60\n",
      "    DRAM Throughput                   %        89.60\n",
      "    Duration                         us        49.79\n",
      "    L1/TEX Cache Throughput           %        31.93\n",
      "    L2 Cache Throughput               %        29.02\n",
      "    SM Active Cycles              cycle    25,313.92\n",
      "    Compute (SM) Throughput           %        24.40\n",
      "    ----------------------- ----------- ------------\n",
      "\n",
      "    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
      "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
      "          Start by analyzing DRAM in the Memory Workload Analysis section.                                              \n",
      "\n",
      "    Section: GPU Speed Of Light Roofline Chart\n",
      "    INF   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       \n",
      "          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel        \n",
      "          Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details  \n",
      "          on roofline analysis.                                                                                         \n",
      "\n",
      "    Section: PM Sampling\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Maximum Buffer Size             Kbyte       262.14\n",
      "    Dropped Samples                sample            0\n",
      "    Maximum Sampling Interval       cycle       20,000\n",
      "    # Pass Groups                                    1\n",
      "    ------------------------- ----------- ------------\n",
      "\n",
      "    Section: Compute Workload Analysis\n",
      "    -------------------- ----------- ------------\n",
      "    Metric Name          Metric Unit Metric Value\n",
      "    -------------------- ----------- ------------\n",
      "    Executed Ipc Active   inst/cycle         0.49\n",
      "    Executed Ipc Elapsed  inst/cycle         0.46\n",
      "    Issue Slots Busy               %        12.23\n",
      "    Issued Ipc Active     inst/cycle         0.49\n",
      "    SM Busy                        %        12.23\n",
      "    -------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 91.91%                                                                                    \n",
      "          All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps   \n",
      "          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             \n",
      "\n",
      "    Section: Memory Workload Analysis\n",
      "    ----------------- ----------- ------------\n",
      "    Metric Name       Metric Unit Metric Value\n",
      "    ----------------- ----------- ------------\n",
      "    Memory Throughput     Gbyte/s       265.04\n",
      "    Mem Busy                    %        29.02\n",
      "    Max Bandwidth               %        89.60\n",
      "    L1/TEX Hit Rate             %            0\n",
      "    L2 Hit Rate                 %        33.58\n",
      "    Mem Pipes Busy              %        24.40\n",
      "    ----------------- ----------- ------------\n",
      "\n",
      "    Section: Memory Workload Analysis Chart\n",
      "    WRN   The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an  \n",
      "          additional metric could enable the rule to provide more guidance.                                             \n",
      "\n",
      "    Section: Scheduler Statistics\n",
      "    ---------------------------- ----------- ------------\n",
      "    Metric Name                  Metric Unit Metric Value\n",
      "    ---------------------------- ----------- ------------\n",
      "    One or More Eligible                   %        12.23\n",
      "    Issued Warp Per Scheduler                        0.12\n",
      "    No Eligible                            %        87.77\n",
      "    Active Warps Per Scheduler          warp         6.22\n",
      "    Eligible Warps Per Scheduler        warp         0.14\n",
      "    ---------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 10.4%                                                                                     \n",
      "          Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      \n",
      "          issues an instruction every 8.2 cycles. This might leave hardware resources underutilized and may lead to     \n",
      "          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    \n",
      "          6.22 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps    \n",
      "          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   \n",
      "          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      \n",
      "          eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp  \n",
      "          State Statistics and Source Counters sections.                                                                \n",
      "\n",
      "    Section: Warp State Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Warp Cycles Per Issued Instruction             cycle        50.88\n",
      "    Warp Cycles Per Executed Instruction           cycle        51.27\n",
      "    Avg. Active Threads Per Warp                                   32\n",
      "    Avg. Not Predicated Off Threads Per Warp                    29.87\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 10.4%                                                                                           \n",
      "          On average, each warp of this kernel spends 39.6 cycles being stalled waiting for a scoreboard dependency on  \n",
      "          a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited     \n",
      "          upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the        \n",
      "          memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by        \n",
      "          increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently     \n",
      "          used data to shared memory. This stall type represents about 77.8% of the total average of 50.9 cycles        \n",
      "          between issuing two instructions.                                                                             \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    INF   Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on         \n",
      "          sampling data. The Kernel Profiling Guide                                                                     \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details    \n",
      "          on each stall reason.                                                                                         \n",
      "\n",
      "    Section: Instruction Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Avg. Executed Instructions Per Scheduler        inst        3,072\n",
      "    Executed Instructions                           inst      491,520\n",
      "    Avg. Issued Instructions Per Scheduler          inst        3,096\n",
      "    Issued Instructions                             inst      495,360\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 4.045%                                                                                          \n",
      "          This kernel executes 0 fused and 32768 non-fused FP32 instructions. By converting pairs of non-fused          \n",
      "          instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point),           \n",
      "          higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its  \n",
      "          current performance). Check the Source page to identify where this kernel executes FP32 instructions.         \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   256\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  4,096\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM              40\n",
      "    Threads                                   thread       1,048,576\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                               25.60\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            4\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        79.58\n",
      "    Achieved Active Warps Per SM           warp        25.47\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 10.4%                                                                                           \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (79.6%) can be the     \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle      206,203\n",
      "    Total DRAM Elapsed Cycles        cycle    1,841,152\n",
      "    Average L1 Active Cycles         cycle    25,313.92\n",
      "    Total L1 Elapsed Cycles          cycle    1,074,200\n",
      "    Average L2 Active Cycles         cycle    36,557.53\n",
      "    Total L2 Elapsed Cycles          cycle    1,361,248\n",
      "    Average SM Active Cycles         cycle    25,313.92\n",
      "    Total SM Elapsed Cycles          cycle    1,074,200\n",
      "    Average SMSP Active Cycles       cycle    25,305.53\n",
      "    Total SMSP Elapsed Cycles        cycle    4,296,800\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    Section: Source Counters\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Branch Instructions Ratio           %         0.13\n",
      "    Branch Instructions              inst       65,536\n",
      "    Branch Efficiency                   %            0\n",
      "    Avg. Divergent Branches                          0\n",
      "    ------------------------- ----------- ------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------- Second loop: re-import reports and show details --------\n",
    "print(\"\\n=== Printing Nsight Compute details for each kernel ===\")\n",
    "for k in kernels:\n",
    "    print(f\"\\n[2] Nsight Compute details page for {k}\")\n",
    "    !NCU_DEFAULTS=\"\" ncu --import profiles/{k}.ncu-rep --page details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6fb2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Running matmul:\")\n",
    "# !./build/bin/matmul\n",
    "\n",
    "# print(\"\\nRunning vec_add:\")\n",
    "# !./build/bin/vec_add\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a74495ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Colab GPU available:\", torch.cuda.is_available())\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c503bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 28 04:50:35 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c5c53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40c22393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmake version 3.31.10\n",
      "\n",
      "CMake suite maintained and supported by Kitware (kitware.com/cmake).\n"
     ]
    }
   ],
   "source": [
    "!cmake --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5b2d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca45e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631aa11b",
   "metadata": {},
   "source": [
    "# Make a new clone from the git repo and then run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38e856e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'GPU_mode'...\n",
      "remote: Enumerating objects: 22, done.\u001b[K\n",
      "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
      "remote: Total 22 (delta 6), reused 22 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (22/22), 5.70 KiB | 5.70 MiB/s, done.\n",
      "Resolving deltas: 100% (6/6), done.\n",
      "/content/GPU_mode\n",
      "CMakelists.txt\tmatrix_multiplication  test_colab_server.ipynb\n",
      "include\t\tREADME.md\t       vector_add\n"
     ]
    }
   ],
   "source": [
    "# Always start from /content\n",
    "%cd /content\n",
    "\n",
    "# Remove any old copies so paths don't get nested\n",
    "!rm -rf GPU_mode\n",
    "\n",
    "# Clone your repo (note the exact repo name in the URL)\n",
    "!git clone https://github.com/parthshinde1221/GPU_mode.git\n",
    "\n",
    "# Enter the repo root\n",
    "%cd GPU_mode\n",
    "\n",
    "# Sanity check: you MUST see CMakeLists.txt here\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f875e",
   "metadata": {},
   "source": [
    "# Building all CUDA kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfcc1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mCMake Error: The source directory \"/content/GPU_mode\" does not appear to contain CMakeLists.txt.\n",
      "Specify --help for usage, or press the help button on the CMake GUI.\u001b[0m\n",
      "Error: /content/GPU_mode/build is not a directory\n"
     ]
    }
   ],
   "source": [
    "# Configure the project (top-level CMakeLists.txt)\n",
    "!cmake -S . -B build -DCMAKE_BUILD_TYPE=Release\n",
    "\n",
    "# Build all targets (matmul, vec_add, etc.)\n",
    "!cmake --build build -j 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe34d054",
   "metadata": {},
   "source": [
    "# Optional build single kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernels = [\"matmul\", \"vec_add\"]  # target names from each CMakeLists.txt\n",
    "\n",
    "# for k in kernels:\n",
    "#     print(f\"\\n=== Building {k} ===\")\n",
    "#     !cmake --build build --target {k} -j 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1df4574",
   "metadata": {},
   "source": [
    "# Running all Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [\"matmul\", \"vec_add\"]  # add more later: \"softmax\", \"conv\", etc.\n",
    "\n",
    "for k in kernels:\n",
    "    print(f\"\\n=== Running {k} ===\")\n",
    "    !./build/bin/{k}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b565db",
   "metadata": {},
   "source": [
    "# CUDA MemCheck all kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2022c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [\"matmul\", \"vec_add\"]\n",
    "\n",
    "for k in kernels:\n",
    "    print(f\"\\n=== cuda-memcheck {k} ===\")\n",
    "    !cuda-memcheck --leak-check full ./build/bin/{k} > profiles/{k}_memcheck.txt 2>&1\n",
    "    print(f\"Saved profiles/{k}_memcheck.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a3ad80",
   "metadata": {},
   "source": [
    "# NCU Profile each kernel all kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bcb975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "import os\n",
    "\n",
    "kernels = [\"matmul\", \"vec_add\"]\n",
    "\n",
    "os.makedirs(\"profiles\", exist_ok=True)\n",
    "\n",
    "for k in kernels:\n",
    "    print(f\"\\n=== Profiling {k} with ncu ===\")\n",
    "    # HTML + .ncu-rep into profiles/<k>.*\n",
    "    !ncu -f --set full --export html -o profiles/{k} ./build/bin/{k}\n",
    "\n",
    "    # Show HTML inline\n",
    "    display(IFrame(f\"profiles/{k}.html\", width=1024, height=600))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6fb2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Running matmul:\")\n",
    "# !./build/bin/matmul\n",
    "\n",
    "# print(\"\\nRunning vec_add:\")\n",
    "# !./build/bin/vec_add\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

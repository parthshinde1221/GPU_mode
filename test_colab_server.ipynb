{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74495ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Colab GPU available:\", torch.cuda.is_available())\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c503bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  2 11:11:54 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   49C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c5c53e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c22393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmake version 3.31.10\n",
      "\n",
      "CMake suite maintained and supported by Kitware (kitware.com/cmake).\n"
     ]
    }
   ],
   "source": [
    "!cmake --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ed1ef",
   "metadata": {},
   "source": [
    "# Run from here always after any change in git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b2d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca45e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631aa11b",
   "metadata": {},
   "source": [
    "# Make a new clone from the git repo and then run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38e856e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'GPU_mode'...\n",
      "remote: Enumerating objects: 92, done.\u001b[K\n",
      "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
      "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
      "remote: Total 92 (delta 48), reused 65 (delta 23), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (92/92), 43.76 KiB | 814.00 KiB/s, done.\n",
      "Resolving deltas: 100% (48/48), done.\n",
      "/content/GPU_mode\n",
      "CMakeLists.txt\tmatrix_multiplication  reduction\t\tvector_add\n",
      "include\t\tREADME.md\t       test_colab_server.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Always start from /content\n",
    "%cd /content\n",
    "\n",
    "# Remove any old copies so paths don't get nested\n",
    "!rm -rf GPU_mode\n",
    "\n",
    "# Clone your repo (note the exact repo name in the URL)\n",
    "!git clone https://github.com/parthshinde1221/GPU_mode.git\n",
    "\n",
    "# Enter the repo root\n",
    "%cd GPU_mode\n",
    "\n",
    "# Sanity check: you MUST see CMakeLists.txt here\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f875e",
   "metadata": {},
   "source": [
    "# Building all CUDA kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfcc1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The CXX compiler identification is GNU 11.4.0\n",
      "-- The CUDA compiler identification is NVIDIA 12.5.82 with host compiler GNU 11.4.0\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Detecting CUDA compiler ABI info\n",
      "-- Detecting CUDA compiler ABI info - done\n",
      "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
      "-- Detecting CUDA compile features\n",
      "-- Detecting CUDA compile features - done\n",
      "-- Adding matmul target: matmul_naive from /content/GPU_mode/matrix_multiplication/matmul_naive.cu\n",
      "-- Adding matmul target: matmul_tiled from /content/GPU_mode/matrix_multiplication/matmul_tiled.cu\n",
      "-- Adding vec_add target: vec_add_naive from /content/GPU_mode/vector_add/vec_add_naive.cu\n",
      "-- Adding vec_add target: vec_add_opt from /content/GPU_mode/vector_add/vec_add_opt.cu\n",
      "-- Adding reduction target: reduce_naive_add from /content/GPU_mode/reduction/reduce_naive_add.cu\n",
      "-- Adding reduction target: reduce_optimized_add from /content/GPU_mode/reduction/reduce_optimized_add.cu\n",
      "-- Configuring done (3.3s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /content/GPU_mode/build\n",
      "[  5%] \u001b[32mBuilding CUDA object vector_add/CMakeFiles/vec_add_naive.dir/vec_add_naive.cu.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CUDA object matrix_multiplication/CMakeFiles/matmul_tiled.dir/matmul_tiled.cu.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CUDA object matrix_multiplication/CMakeFiles/matmul_naive.dir/matmul_naive.cu.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding CUDA object vector_add/CMakeFiles/vec_add_opt.dir/vec_add_opt.cu.o\u001b[0m\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/matrix_multiplication/matmul_naive.cu(22)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"sum\"\u001b[0m was declared but never referenced\n",
      "          float sum = 0.0f;\n",
      "                ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/matrix_multiplication/matmul_naive.cu(22)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"sum\"\u001b[0m was declared but never referenced\n",
      "          float sum = 0.0f;\n",
      "                ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/matrix_multiplication/matmul_naive.cu(22)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"sum\"\u001b[0m was declared but never referenced\n",
      "          float sum = 0.0f;\n",
      "                ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/matrix_multiplication/matmul_naive.cu(22)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"sum\"\u001b[0m was declared but never referenced\n",
      "          float sum = 0.0f;\n",
      "                ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "[ 27%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/vec_add_naive.dir/cmake_device_link.o\u001b[0m\n",
      "[ 33%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/vec_add_naive\u001b[0m\n",
      "[ 33%] Built target vec_add_naive\n",
      "[ 38%] \u001b[32mBuilding CUDA object reduction/CMakeFiles/reduce_naive_add.dir/reduce_naive_add.cu.o\u001b[0m\n",
      "[ 44%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/matmul_tiled.dir/cmake_device_link.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/vec_add_opt.dir/cmake_device_link.o\u001b[0m\n",
      "[ 55%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/matmul_tiled\u001b[0m\n",
      "[ 61%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/vec_add_opt\u001b[0m\n",
      "[ 66%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/matmul_naive.dir/cmake_device_link.o\u001b[0m\n",
      "[ 66%] Built target matmul_tiled\n",
      "[ 72%] \u001b[32mBuilding CUDA object reduction/CMakeFiles/reduce_optimized_add.dir/reduce_optimized_add.cu.o\u001b[0m\n",
      "[ 72%] Built target vec_add_opt\n",
      "[ 77%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/matmul_naive\u001b[0m\n",
      "[ 77%] Built target matmul_naive\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(132)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"rel_eps\"\u001b[0m was declared but never referenced\n",
      "      float rel_eps = 1e-5f;\n",
      "            ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(133)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"abs_eps\"\u001b[0m was declared but never referenced\n",
      "      float abs_eps = 1e-6f;\n",
      "            ^\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(132)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"rel_eps\"\u001b[0m was declared but never referenced\n",
      "      float rel_eps = 1e-5f;\n",
      "            ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(133)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"abs_eps\"\u001b[0m was declared but never referenced\n",
      "      float abs_eps = 1e-6f;\n",
      "            ^\n",
      "\n",
      "[ 83%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/reduce_optimized_add.dir/cmake_device_link.o\u001b[0m\n",
      "[ 88%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/reduce_optimized_add\u001b[0m\n",
      "/usr/bin/ld: /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/Scrt1.o: in function `_start':\n",
      "(.text+0x1b): undefined reference to `main'\n",
      "collect2: error: ld returned 1 exit status\n",
      "gmake[2]: *** [reduction/CMakeFiles/reduce_optimized_add.dir/build.make:123: bin/reduce_optimized_add] Error 1\n",
      "gmake[1]: *** [CMakeFiles/Makefile2:321: reduction/CMakeFiles/reduce_optimized_add.dir/all] Error 2\n",
      "gmake[1]: *** Waiting for unfinished jobs....\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(132)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"rel_eps\"\u001b[0m was declared but never referenced\n",
      "      float rel_eps = 1e-5f;\n",
      "            ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(133)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"abs_eps\"\u001b[0m was declared but never referenced\n",
      "      float abs_eps = 1e-6f;\n",
      "            ^\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(132)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"rel_eps\"\u001b[0m was declared but never referenced\n",
      "      float rel_eps = 1e-5f;\n",
      "            ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(133)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"abs_eps\"\u001b[0m was declared but never referenced\n",
      "      float abs_eps = 1e-6f;\n",
      "            ^\n",
      "\n",
      "[ 94%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/reduce_naive_add.dir/cmake_device_link.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/reduce_naive_add\u001b[0m\n",
      "[100%] Built target reduce_naive_add\n",
      "gmake: *** [Makefile:91: all] Error 2\n"
     ]
    }
   ],
   "source": [
    "# Configure the project (top-level CMakeLists.txt)\n",
    "!cmake -S . -B build -DCMAKE_BUILD_TYPE=Release\n",
    "\n",
    "# Build all targets (matmul, vec_add, etc.)\n",
    "!cmake --build build -j 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe34d054",
   "metadata": {},
   "source": [
    "# Optional build single kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0125bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernels = [\"matmul\", \"vec_add\"]  # target names from each CMakeLists.txt\n",
    "\n",
    "# for k in kernels:\n",
    "#     print(f\"\\n=== Building {k} ===\")\n",
    "#     !cmake --build build --target {k} -j 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1df4574",
   "metadata": {},
   "source": [
    "# Running all Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b33cd202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global kernels\n",
    "# kernels = [\"reduce_naive_add\"]\n",
    "# kernels = [\"vec_add_naive\",\"vec_add_opt\"]  # add more later: \"softmax\", \"conv\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d424f05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running matmul_naive ===\n",
      "C[0] = 1024 (expected 1024)\n",
      "\n",
      "=== Running vec_add_naive ===\n",
      "c[0] = 3 (expected 3)\n",
      "c[N-1] = 3 (expected 3)\n",
      "\n",
      "=== Running matmul_tiled ===\n",
      "[tiled] C[0] = 1024 (expected 1024)\n",
      "\n",
      "=== Running vec_add_opt ===\n",
      "c[0] = 3 (expected 3)\n",
      "c[N-1] = 3 (expected 3)\n",
      "\n",
      "=== Running reduce_naive_add ===\n",
      "CPU sum: 1.57286e+06 | GPU sum: 1.57286e+06 | diff: 0\n"
     ]
    }
   ],
   "source": [
    "kernels = [\"matmul_naive\", \"vec_add_naive\",\"matmul_tiled\",\"vec_add_opt\",\"reduce_naive_add\"]  # add more later: \"softmax\", \"conv\", etc.\n",
    "\n",
    "for k in kernels:\n",
    "    print(f\"\\n=== Running {k} ===\")\n",
    "    !./build/bin/{k}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b565db",
   "metadata": {},
   "source": [
    "# CUDA MemCheck all kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a30afd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aa92b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\tmatrix_multiplication  reduction\n",
      "CMakeLists.txt\tprofiles\t       test_colab_server.ipynb\n",
      "include\t\tREADME.md\t       vector_add\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d28f099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !which cuda-memcheck\n",
    "# !which compute-sanitizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2022c2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== compute-sanitizer (memcheck) on matmul_naive ===\n",
      "Saved profiles/matmul_naive_memcheck.txt\n",
      "========= COMPUTE-SANITIZER\n",
      "C[0] = 1024 (expected 1024)\n",
      "========= ERROR SUMMARY: 0 errors\n",
      "\n",
      "=== compute-sanitizer (racecheck) on matmul_naive ===\n",
      "Saved profiles/matmul_naive_racecheck.txt\n",
      "========= COMPUTE-SANITIZER\n",
      "C[0] = 1024 (expected 1024)\n",
      "========= RACECHECK SUMMARY: 0 hazards displayed (0 errors, 0 warnings)\n",
      "\n",
      "=== compute-sanitizer (memcheck) on vec_add_naive ===\n",
      "Saved profiles/vec_add_naive_memcheck.txt\n",
      "========= COMPUTE-SANITIZER\n",
      "c[0] = 3 (expected 3)\n",
      "c[N-1] = 3 (expected 3)\n",
      "========= ERROR SUMMARY: 0 errors\n",
      "\n",
      "=== compute-sanitizer (racecheck) on vec_add_naive ===\n",
      "Saved profiles/vec_add_naive_racecheck.txt\n",
      "========= COMPUTE-SANITIZER\n",
      "c[0] = 3 (expected 3)\n",
      "c[N-1] = 3 (expected 3)\n",
      "========= RACECHECK SUMMARY: 0 hazards displayed (0 errors, 0 warnings)\n",
      "\n",
      "=== compute-sanitizer (memcheck) on matmul_tiled ===\n",
      "Saved profiles/matmul_tiled_memcheck.txt\n",
      "========= COMPUTE-SANITIZER\n",
      "[tiled] C[0] = 1024 (expected 1024)\n",
      "========= ERROR SUMMARY: 0 errors\n",
      "\n",
      "=== compute-sanitizer (racecheck) on matmul_tiled ===\n",
      "Saved profiles/matmul_tiled_racecheck.txt\n",
      "========= COMPUTE-SANITIZER\n",
      "[tiled] C[0] = 1024 (expected 1024)\n",
      "========= RACECHECK SUMMARY: 0 hazards displayed (0 errors, 0 warnings)\n",
      "\n",
      "=== compute-sanitizer (memcheck) on vec_add_opt ===\n",
      "Saved profiles/vec_add_opt_memcheck.txt\n",
      "========= COMPUTE-SANITIZER\n",
      "c[0] = 3 (expected 3)\n",
      "c[N-1] = 3 (expected 3)\n",
      "========= ERROR SUMMARY: 0 errors\n",
      "\n",
      "=== compute-sanitizer (racecheck) on vec_add_opt ===\n",
      "Saved profiles/vec_add_opt_racecheck.txt\n",
      "========= COMPUTE-SANITIZER\n",
      "c[0] = 3 (expected 3)\n",
      "c[N-1] = 3 (expected 3)\n",
      "========= RACECHECK SUMMARY: 0 hazards displayed (0 errors, 0 warnings)\n",
      "\n",
      "=== compute-sanitizer (memcheck) on reduce_naive_add ===\n",
      "Saved profiles/reduce_naive_add_memcheck.txt\n",
      "========= COMPUTE-SANITIZER\n",
      "CPU sum: 1.57286e+06 | GPU sum: 1.57286e+06 | diff: 0\n",
      "========= ERROR SUMMARY: 0 errors\n",
      "\n",
      "=== compute-sanitizer (racecheck) on reduce_naive_add ===\n",
      "Saved profiles/reduce_naive_add_racecheck.txt\n",
      "========= COMPUTE-SANITIZER\n",
      "CPU sum: 1.57286e+06 | GPU sum: 1.57286e+06 | diff: 0\n",
      "========= RACECHECK SUMMARY: 0 hazards displayed (0 errors, 0 warnings)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"profiles\", exist_ok=True)\n",
    "\n",
    "tools   = [\"memcheck\", \"racecheck\"]\n",
    "# kernels = [\"matmul_naive\", \"vec_add_naive\", \"matmul_tiled\", \"vec_add_opt\"]\n",
    "\n",
    "for k in kernels:\n",
    "    for t in tools:\n",
    "        print(f\"\\n=== compute-sanitizer ({t}) on {k} ===\")\n",
    "        log = f\"profiles/{k}_{t}.txt\"\n",
    "        !compute-sanitizer --tool {t} ./build/bin/{k} > {log} 2>&1\n",
    "        print(f\"Saved {log}\")\n",
    "        !tail -n 20 {log}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a3ad80",
   "metadata": {},
   "source": [
    "# NCU Profile each kernel all kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c77d5334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\tmatrix_multiplication  reduction\n",
      "CMakeLists.txt\tprofiles\t       test_colab_server.ipynb\n",
      "include\t\tREADME.md\t       vector_add\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a9463e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin\t\tCMakeFiles\t     Makefile\t\t    reduction\n",
      "CMakeCache.txt\tcmake_install.cmake  matrix_multiplication  vector_add\n"
     ]
    }
   ],
   "source": [
    "!ls build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae20b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_naive  matmul_tiled  reduce_naive_add  vec_add_naive  vec_add_opt\n"
     ]
    }
   ],
   "source": [
    "!ls build/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3bcb975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import IFrame\n",
    "# import os\n",
    "\n",
    "# os.makedirs(\"profiles\", exist_ok=True)\n",
    "\n",
    "# kernels = [\"matmul\", \"vec_add\"]\n",
    "\n",
    "# for k in kernels:\n",
    "#     print(f\"\\n=== Profiling {k} with ncu ===\")\n",
    "#     # NCU_DEFAULTS=\"\" clears any default --export that Colab may set\n",
    "#     !NCU_DEFAULTS=\"\" ncu -f --set full --export html -o profiles/{k} ./build/bin/{k}\n",
    "#     display(IFrame(f\"profiles/{k}.html\", width=1024, height=600))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12bad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running Nsight Compute and saving reports ===\n",
      "\n",
      "[1] Profiling matmul_naive with ncu ...\n",
      "==PROF== Connected to process 1797 (/content/GPU_mode/build/bin/matmul_naive)\n",
      "==PROF== Profiling \"matmul_kernel\" - 0: 0%....50%....100% - 30 passes\n",
      "C[0] = 1024 (expected 1024)\n",
      "==PROF== Disconnected from process 1797\n",
      "==PROF== Report: /content/GPU_mode/profiles/matmul_naive.ncu-rep\n",
      "--> Saved report: profiles/matmul_naive.ncu-rep\n",
      "--> Duration for matmul_naive:\n",
      "    Duration                         ms         2.08\n",
      "\n",
      "[1] Profiling vec_add_naive with ncu ...\n",
      "==PROF== Connected to process 1894 (/content/GPU_mode/build/bin/vec_add_naive)\n",
      "==PROF== Profiling \"vec_add_kernel\" - 0: 0%....50%....100% - 30 passes\n",
      "c[0] = 3 (expected 3)\n",
      "c[N-1] = 3 (expected 3)\n",
      "==PROF== Disconnected from process 1894\n",
      "==PROF== Report: /content/GPU_mode/profiles/vec_add_naive.ncu-rep\n",
      "--> Saved report: profiles/vec_add_naive.ncu-rep\n",
      "--> Duration for vec_add_naive:\n",
      "    Duration                         us        49.02\n",
      "\n",
      "[1] Profiling matmul_tiled with ncu ...\n",
      "==PROF== Connected to process 1991 (/content/GPU_mode/build/bin/matmul_tiled)\n",
      "==PROF== Profiling \"matmul_tiled_kernel\" - 0: 0%....50%....100% - 30 passes\n",
      "[tiled] C[0] = 1024 (expected 1024)\n",
      "==PROF== Disconnected from process 1991\n",
      "==PROF== Report: /content/GPU_mode/profiles/matmul_tiled.ncu-rep\n",
      "--> Saved report: profiles/matmul_tiled.ncu-rep\n",
      "--> Duration for matmul_tiled:\n",
      "    Duration                         us       937.89\n",
      "\n",
      "[1] Profiling vec_add_opt with ncu ...\n",
      "==PROF== Connected to process 2088 (/content/GPU_mode/build/bin/vec_add_opt)\n",
      "==PROF== Profiling \"vec_add_kernel\" - 0: 0%....50%....100% - 30 passes\n",
      "c[0] = 3 (expected 3)\n",
      "c[N-1] = 3 (expected 3)\n",
      "==PROF== Disconnected from process 2088\n",
      "==PROF== Report: /content/GPU_mode/profiles/vec_add_opt.ncu-rep\n",
      "--> Saved report: profiles/vec_add_opt.ncu-rep\n",
      "--> Duration for vec_add_opt:\n",
      "    Duration                         us        53.82\n",
      "\n",
      "[1] Profiling reduce_naive_add with ncu ...\n",
      "==PROF== Connected to process 2191 (/content/GPU_mode/build/bin/reduce_naive_add)\n",
      "==PROF== Profiling \"naive_add\" - 0: 0%....50%....100% - 30 passes\n",
      "CPU sum: 1.57286e+06 | GPU sum: 1.57286e+06 | diff: 0\n",
      "==PROF== Disconnected from process 2191\n",
      "==PROF== Report: /content/GPU_mode/profiles/reduce_naive_add.ncu-rep\n",
      "--> Saved report: profiles/reduce_naive_add.ncu-rep\n",
      "--> Duration for reduce_naive_add:\n",
      "    Duration                         ms         3.82\n",
      "\n",
      "All reports saved:\n",
      "total 1.2M\n",
      "-rw-r--r-- 1 root root   90 Dec  2 11:12 matmul_naive_memcheck.txt\n",
      "-rw-r--r-- 1 root root 283K Dec  2 11:13 matmul_naive.ncu-rep\n",
      "-rw-r--r-- 1 root root  128 Dec  2 11:12 matmul_naive_racecheck.txt\n",
      "-rw-r--r-- 1 root root   98 Dec  2 11:12 matmul_tiled_memcheck.txt\n",
      "-rw-r--r-- 1 root root 246K Dec  2 11:13 matmul_tiled.ncu-rep\n",
      "-rw-r--r-- 1 root root  136 Dec  2 11:13 matmul_tiled_racecheck.txt\n",
      "-rw-r--r-- 1 root root  116 Dec  2 11:13 reduce_naive_add_memcheck.txt\n",
      "-rw-r--r-- 1 root root 219K Dec  2 11:13 reduce_naive_add.ncu-rep\n",
      "-rw-r--r-- 1 root root  154 Dec  2 11:13 reduce_naive_add_racecheck.txt\n",
      "-rw-r--r-- 1 root root  108 Dec  2 11:12 vec_add_naive_memcheck.txt\n",
      "-rw-r--r-- 1 root root 186K Dec  2 11:13 vec_add_naive.ncu-rep\n",
      "-rw-r--r-- 1 root root  146 Dec  2 11:12 vec_add_naive_racecheck.txt\n",
      "-rw-r--r-- 1 root root  108 Dec  2 11:13 vec_add_opt_memcheck.txt\n",
      "-rw-r--r-- 1 root root 218K Dec  2 11:13 vec_add_opt.ncu-rep\n",
      "-rw-r--r-- 1 root root  146 Dec  2 11:13 vec_add_opt_racecheck.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"profiles\", exist_ok=True)\n",
    "\n",
    "# kernels = [\"matmul_naive\", \"matmul_tiled\",\"vec_add_naive\",\"vec_add_opt\"]\n",
    "\n",
    "# -------- First loop: run profiling & save reports --------\n",
    "print(\"=== Running Nsight Compute and saving reports ===\")\n",
    "for k in kernels:\n",
    "    print(f\"\\n[1] Profiling {k} with ncu ...\")\n",
    "    !NCU_DEFAULTS=\"\" ncu -f --set full -o profiles/{k} ./build/bin/{k}\n",
    "    print(f\"--> Saved report: profiles/{k}.ncu-rep\")\n",
    "    \n",
    "    # Print the kernel Duration from the report\n",
    "    print(f\"--> Duration for {k}:\")\n",
    "    !NCU_DEFAULTS=\"\" ncu --import profiles/{k}.ncu-rep --page details | grep \"Duration\"\n",
    "\n",
    "print(\"\\nAll reports saved:\")\n",
    "!ls -lh profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65407218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Printing Nsight Compute details for each kernel ===\n",
      "\n",
      "[2] Nsight Compute details page for matmul_naive\n",
      "[1797] matmul_naive@127.0.0.1\n",
      "  matmul_kernel(const float *, const float *, float *, int) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ----------- ------------\n",
      "    Metric Name             Metric Unit Metric Value\n",
      "    ----------------------- ----------- ------------\n",
      "    DRAM Frequency                  Ghz         4.99\n",
      "    SM Frequency                    Mhz       584.98\n",
      "    Elapsed Cycles                cycle    1,218,168\n",
      "    Memory Throughput                 %        51.76\n",
      "    DRAM Throughput                   %         0.98\n",
      "    Duration                         ms         2.08\n",
      "    L1/TEX Cache Throughput           %        95.72\n",
      "    L2 Cache Throughput               %        34.24\n",
      "    SM Active Cycles              cycle 1,195,125.77\n",
      "    Compute (SM) Throughput           %        51.76\n",
      "    ----------------------- ----------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: GPU Speed Of Light Roofline Chart\n",
      "    INF   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 4% of \n",
      "          this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide       \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline      \n",
      "          analysis.                                                                                                     \n",
      "\n",
      "    Section: PM Sampling\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Maximum Buffer Size             Mbyte         3.80\n",
      "    Dropped Samples                sample            0\n",
      "    Maximum Sampling Interval       cycle       80,000\n",
      "    # Pass Groups                                    1\n",
      "    ------------------------- ----------- ------------\n",
      "\n",
      "    Section: Compute Workload Analysis\n",
      "    -------------------- ----------- ------------\n",
      "    Metric Name          Metric Unit Metric Value\n",
      "    -------------------- ----------- ------------\n",
      "    Executed Ipc Active   inst/cycle         0.49\n",
      "    Executed Ipc Elapsed  inst/cycle         0.49\n",
      "    Issue Slots Busy               %        12.37\n",
      "    Issued Ipc Active     inst/cycle         0.49\n",
      "    SM Busy                        %        17.60\n",
      "    -------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 90.89%                                                                                    \n",
      "          All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps   \n",
      "          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             \n",
      "\n",
      "    Section: Memory Workload Analysis\n",
      "    ----------------- ----------- ------------\n",
      "    Metric Name       Metric Unit Metric Value\n",
      "    ----------------- ----------- ------------\n",
      "    Memory Throughput     Gbyte/s         3.14\n",
      "    Mem Busy                    %        47.77\n",
      "    Max Bandwidth               %        51.76\n",
      "    L1/TEX Hit Rate             %        93.74\n",
      "    L2 Hit Rate                 %        99.57\n",
      "    Mem Pipes Busy              %        51.76\n",
      "    ----------------- ----------- ------------\n",
      "\n",
      "    Section: Memory Workload Analysis Chart\n",
      "    WRN   The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an  \n",
      "          additional metric could enable the rule to provide more guidance.                                             \n",
      "\n",
      "    Section: Memory Workload Analysis Tables\n",
      "    OPT   Est. Speedup: 41.79%                                                                                          \n",
      "          The memory access pattern for global loads from L1TEX might not be optimal. On average, only 18.0 of the 32   \n",
      "          bytes transmitted per sector are utilized by each thread. This could possibly be caused by a stride between   \n",
      "          threads. Check the Source Counters section for uncoalesced global loads.                                      \n",
      "\n",
      "    Section: Scheduler Statistics\n",
      "    ---------------------------- ----------- ------------\n",
      "    Metric Name                  Metric Unit Metric Value\n",
      "    ---------------------------- ----------- ------------\n",
      "    One or More Eligible                   %        12.34\n",
      "    Issued Warp Per Scheduler                        0.12\n",
      "    No Eligible                            %        87.66\n",
      "    Active Warps Per Scheduler          warp         7.67\n",
      "    Eligible Warps Per Scheduler        warp         0.29\n",
      "    ---------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 48.24%                                                                                    \n",
      "          Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      \n",
      "          issues an instruction every 8.1 cycles. This might leave hardware resources underutilized and may lead to     \n",
      "          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    \n",
      "          7.67 active warps per scheduler, but only an average of 0.29 warps were eligible per cycle. Eligible warps    \n",
      "          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   \n",
      "          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      \n",
      "          eligible warps, avoid possible load imbalances due to highly different execution durations per warp.          \n",
      "          Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.            \n",
      "\n",
      "    Section: Warp State Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Warp Cycles Per Issued Instruction             cycle        62.12\n",
      "    Warp Cycles Per Executed Instruction           cycle        62.13\n",
      "    Avg. Active Threads Per Warp                                   32\n",
      "    Avg. Not Predicated Off Threads Per Warp                    31.94\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 48.24%                                                                                          \n",
      "          On average, each warp of this kernel spends 34.2 cycles being stalled waiting for a scoreboard dependency on  \n",
      "          a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited     \n",
      "          upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the        \n",
      "          memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by        \n",
      "          increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently     \n",
      "          used data to shared memory. This stall type represents about 55.0% of the total average of 62.1 cycles        \n",
      "          between issuing two instructions.                                                                             \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    OPT   Est. Speedup: 35.96%                                                                                          \n",
      "          On average, each warp of this kernel spends 22.3 cycles being stalled waiting for the L1 instruction queue    \n",
      "          for local and global (LG) memory operations to be not full. Typically, this stall occurs only when executing  \n",
      "          local or global memory instructions extremely frequently. Avoid redundant global memory accesses. Try to      \n",
      "          avoid using thread-local memory by checking if dynamically indexed arrays are declared in local scope, of if  \n",
      "          the kernel has excessive register pressure causing by spills. If applicable, consider combining multiple      \n",
      "          lower-width memory operations into fewer wider memory operations and try interleaving memory operations and   \n",
      "          math instructions. This stall type represents about 36.0% of the total average of 62.1 cycles between         \n",
      "          issuing two instructions.                                                                                     \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    INF   Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on         \n",
      "          sampling data. The Kernel Profiling Guide                                                                     \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details    \n",
      "          on each stall reason.                                                                                         \n",
      "\n",
      "    Section: Instruction Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Avg. Executed Instructions Per Scheduler        inst   147,763.20\n",
      "    Executed Instructions                           inst   23,642,112\n",
      "    Avg. Issued Instructions Per Scheduler          inst   147,788.51\n",
      "    Issued Instructions                             inst   23,646,162\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   256\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  1,024\n",
      "    Registers Per Thread             register/thread              28\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM              40\n",
      "    Threads                                   thread         262,144\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                6.40\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            8\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            4\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        95.91\n",
      "    Achieved Active Warps Per SM           warp        30.69\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle   102,121.50\n",
      "    Total DRAM Elapsed Cycles        cycle   83,159,040\n",
      "    Average L1 Active Cycles         cycle 1,195,125.77\n",
      "    Total L1 Elapsed Cycles          cycle   48,718,296\n",
      "    Average L2 Active Cycles         cycle    1,698,647\n",
      "    Total L2 Elapsed Cycles          cycle   54,966,752\n",
      "    Average SM Active Cycles         cycle 1,195,125.77\n",
      "    Total SM Elapsed Cycles          cycle   48,718,296\n",
      "    Average SMSP Active Cycles       cycle 1,197,759.96\n",
      "    Total SMSP Elapsed Cycles        cycle  194,873,184\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    Section: Source Counters\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Branch Instructions Ratio           %         0.01\n",
      "    Branch Instructions              inst      319,488\n",
      "    Branch Efficiency                   %          100\n",
      "    Avg. Divergent Branches                          0\n",
      "    ------------------------- ----------- ------------\n",
      "\n",
      "\n",
      "[2] Nsight Compute details page for vec_add_naive\n",
      "[1894] vec_add_naive@127.0.0.1\n",
      "  vec_add_kernel(const float *, const float *, float *, int) (4096, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ----------- ------------\n",
      "    Metric Name             Metric Unit Metric Value\n",
      "    ----------------------- ----------- ------------\n",
      "    DRAM Frequency                  Ghz         4.65\n",
      "    SM Frequency                    Mhz       583.97\n",
      "    Elapsed Cycles                cycle       28,635\n",
      "    Memory Throughput                 %        88.85\n",
      "    DRAM Throughput                   %        88.85\n",
      "    Duration                         us        49.02\n",
      "    L1/TEX Cache Throughput           %        32.09\n",
      "    L2 Cache Throughput               %        30.80\n",
      "    SM Active Cycles              cycle    24,997.92\n",
      "    Compute (SM) Throughput           %        24.54\n",
      "    ----------------------- ----------- ------------\n",
      "\n",
      "    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
      "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
      "          Start by analyzing DRAM in the Memory Workload Analysis section.                                              \n",
      "\n",
      "    Section: GPU Speed Of Light Roofline Chart\n",
      "    INF   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       \n",
      "          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel        \n",
      "          Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details  \n",
      "          on roofline analysis.                                                                                         \n",
      "\n",
      "    Section: PM Sampling\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Maximum Buffer Size             Kbyte       262.14\n",
      "    Dropped Samples                sample            0\n",
      "    Maximum Sampling Interval       cycle       20,000\n",
      "    # Pass Groups                                    1\n",
      "    ------------------------- ----------- ------------\n",
      "\n",
      "    Section: Compute Workload Analysis\n",
      "    -------------------- ----------- ------------\n",
      "    Metric Name          Metric Unit Metric Value\n",
      "    -------------------- ----------- ------------\n",
      "    Executed Ipc Active   inst/cycle         0.49\n",
      "    Executed Ipc Elapsed  inst/cycle         0.46\n",
      "    Issue Slots Busy               %        12.39\n",
      "    Issued Ipc Active     inst/cycle         0.50\n",
      "    SM Busy                        %        12.39\n",
      "    -------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 91.81%                                                                                    \n",
      "          All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps   \n",
      "          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             \n",
      "\n",
      "    Section: Memory Workload Analysis\n",
      "    ----------------- ----------- ------------\n",
      "    Metric Name       Metric Unit Metric Value\n",
      "    ----------------- ----------- ------------\n",
      "    Memory Throughput     Gbyte/s       264.58\n",
      "    Mem Busy                    %        30.80\n",
      "    Max Bandwidth               %        88.85\n",
      "    L1/TEX Hit Rate             %            0\n",
      "    L2 Hit Rate                 %        33.59\n",
      "    Mem Pipes Busy              %        24.54\n",
      "    ----------------- ----------- ------------\n",
      "\n",
      "    Section: Memory Workload Analysis Chart\n",
      "    WRN   The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an  \n",
      "          additional metric could enable the rule to provide more guidance.                                             \n",
      "\n",
      "    Section: Scheduler Statistics\n",
      "    ---------------------------- ----------- ------------\n",
      "    Metric Name                  Metric Unit Metric Value\n",
      "    ---------------------------- ----------- ------------\n",
      "    One or More Eligible                   %        12.43\n",
      "    Issued Warp Per Scheduler                        0.12\n",
      "    No Eligible                            %        87.57\n",
      "    Active Warps Per Scheduler          warp         6.23\n",
      "    Eligible Warps Per Scheduler        warp         0.15\n",
      "    ---------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 11.15%                                                                                    \n",
      "          Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      \n",
      "          issues an instruction every 8.0 cycles. This might leave hardware resources underutilized and may lead to     \n",
      "          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    \n",
      "          6.23 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    \n",
      "          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   \n",
      "          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      \n",
      "          eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp  \n",
      "          State Statistics and Source Counters sections.                                                                \n",
      "\n",
      "    Section: Warp State Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Warp Cycles Per Issued Instruction             cycle        50.15\n",
      "    Warp Cycles Per Executed Instruction           cycle        50.55\n",
      "    Avg. Active Threads Per Warp                                   32\n",
      "    Avg. Not Predicated Off Threads Per Warp                    29.87\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 11.15%                                                                                          \n",
      "          On average, each warp of this kernel spends 39.3 cycles being stalled waiting for a scoreboard dependency on  \n",
      "          a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited     \n",
      "          upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the        \n",
      "          memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by        \n",
      "          increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently     \n",
      "          used data to shared memory. This stall type represents about 78.4% of the total average of 50.2 cycles        \n",
      "          between issuing two instructions.                                                                             \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    INF   Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on         \n",
      "          sampling data. The Kernel Profiling Guide                                                                     \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details    \n",
      "          on each stall reason.                                                                                         \n",
      "\n",
      "    Section: Instruction Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Avg. Executed Instructions Per Scheduler        inst        3,072\n",
      "    Executed Instructions                           inst      491,520\n",
      "    Avg. Issued Instructions Per Scheduler          inst        3,096\n",
      "    Issued Instructions                             inst      495,360\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 4.096%                                                                                          \n",
      "          This kernel executes 0 fused and 32768 non-fused FP32 instructions. By converting pairs of non-fused          \n",
      "          instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point),           \n",
      "          higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its  \n",
      "          current performance). Check the Source page to identify where this kernel executes FP32 instructions.         \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   256\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  4,096\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM              40\n",
      "    Threads                                   thread       1,048,576\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                               25.60\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            4\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        80.13\n",
      "    Achieved Active Warps Per SM           warp        25.64\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 11.15%                                                                                          \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (80.1%) can be the     \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle      202,668\n",
      "    Total DRAM Elapsed Cycles        cycle    1,824,768\n",
      "    Average L1 Active Cycles         cycle    24,997.92\n",
      "    Total L1 Elapsed Cycles          cycle    1,068,232\n",
      "    Average L2 Active Cycles         cycle    34,469.66\n",
      "    Total L2 Elapsed Cycles          cycle    1,282,016\n",
      "    Average SM Active Cycles         cycle    24,997.92\n",
      "    Total SM Elapsed Cycles          cycle    1,068,232\n",
      "    Average SMSP Active Cycles       cycle    24,912.68\n",
      "    Total SMSP Elapsed Cycles        cycle    4,272,928\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    Section: Source Counters\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Branch Instructions Ratio           %         0.13\n",
      "    Branch Instructions              inst       65,536\n",
      "    Branch Efficiency                   %            0\n",
      "    Avg. Divergent Branches                          0\n",
      "    ------------------------- ----------- ------------\n",
      "\n",
      "\n",
      "[2] Nsight Compute details page for matmul_tiled\n",
      "[1991] matmul_tiled@127.0.0.1\n",
      "  matmul_tiled_kernel(const float *, const float *, float *, int) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ----------- ------------\n",
      "    Metric Name             Metric Unit Metric Value\n",
      "    ----------------------- ----------- ------------\n",
      "    DRAM Frequency                  Ghz         5.00\n",
      "    SM Frequency                    Mhz       584.97\n",
      "    Elapsed Cycles                cycle      548,641\n",
      "    Memory Throughput                 %        86.30\n",
      "    DRAM Throughput                   %         1.46\n",
      "    Duration                         us       937.89\n",
      "    L1/TEX Cache Throughput           %        92.95\n",
      "    L2 Cache Throughput               %         8.22\n",
      "    SM Active Cycles              cycle   538,468.93\n",
      "    Compute (SM) Throughput           %        86.30\n",
      "    ----------------------- ----------- ------------\n",
      "\n",
      "    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
      "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
      "          Start by analyzing workloads in the Compute Workload Analysis section.                                        \n",
      "\n",
      "    Section: GPU Speed Of Light Roofline Chart\n",
      "    INF   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 10%   \n",
      "          of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide    \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline      \n",
      "          analysis.                                                                                                     \n",
      "\n",
      "    Section: PM Sampling\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Maximum Buffer Size             Mbyte         3.34\n",
      "    Dropped Samples                sample            0\n",
      "    Maximum Sampling Interval       cycle       40,000\n",
      "    # Pass Groups                                    1\n",
      "    ------------------------- ----------- ------------\n",
      "\n",
      "    Section: Compute Workload Analysis\n",
      "    -------------------- ----------- ------------\n",
      "    Metric Name          Metric Unit Metric Value\n",
      "    -------------------- ----------- ------------\n",
      "    Executed Ipc Active   inst/cycle         0.90\n",
      "    Executed Ipc Elapsed  inst/cycle         0.89\n",
      "    Issue Slots Busy               %        22.55\n",
      "    Issued Ipc Active     inst/cycle         0.90\n",
      "    SM Busy                        %        30.96\n",
      "    -------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 89.43%                                                                                    \n",
      "          All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps   \n",
      "          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             \n",
      "\n",
      "    Section: Memory Workload Analysis\n",
      "    ----------------- ----------- ------------\n",
      "    Metric Name       Metric Unit Metric Value\n",
      "    ----------------- ----------- ------------\n",
      "    Memory Throughput     Gbyte/s         4.68\n",
      "    Mem Busy                    %        46.48\n",
      "    Max Bandwidth               %        86.30\n",
      "    L1/TEX Hit Rate             %         4.96\n",
      "    L2 Hit Rate                 %        95.99\n",
      "    Mem Pipes Busy              %        86.30\n",
      "    ----------------- ----------- ------------\n",
      "\n",
      "    Section: Memory Workload Analysis Chart\n",
      "    WRN   The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an  \n",
      "          additional metric could enable the rule to provide more guidance.                                             \n",
      "\n",
      "    Section: Scheduler Statistics\n",
      "    ---------------------------- ----------- ------------\n",
      "    Metric Name                  Metric Unit Metric Value\n",
      "    ---------------------------- ----------- ------------\n",
      "    One or More Eligible                   %        22.56\n",
      "    Issued Warp Per Scheduler                        0.23\n",
      "    No Eligible                            %        77.44\n",
      "    Active Warps Per Scheduler          warp         7.57\n",
      "    Eligible Warps Per Scheduler        warp         0.85\n",
      "    ---------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 13.7%                                                                                     \n",
      "          Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      \n",
      "          issues an instruction every 4.4 cycles. This might leave hardware resources underutilized and may lead to     \n",
      "          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    \n",
      "          7.57 active warps per scheduler, but only an average of 0.85 warps were eligible per cycle. Eligible warps    \n",
      "          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   \n",
      "          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      \n",
      "          eligible warps, avoid possible load imbalances due to highly different execution durations per warp.          \n",
      "          Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.            \n",
      "\n",
      "    Section: Warp State Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Warp Cycles Per Issued Instruction             cycle        33.58\n",
      "    Warp Cycles Per Executed Instruction           cycle        33.59\n",
      "    Avg. Active Threads Per Warp                                   32\n",
      "    Avg. Not Predicated Off Threads Per Warp                    31.96\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 13.7%                                                                                           \n",
      "          On average, each warp of this kernel spends 20.1 cycles being stalled waiting for the MIO (memory             \n",
      "          input/output) instruction queue to be not full. This stall reason is high in cases of extreme utilization of  \n",
      "          the MIO pipelines, which include special math instructions, dynamic branches, as well as shared memory        \n",
      "          instructions. When caused by shared memory accesses, trying to use fewer but wider loads can reduce pipeline  \n",
      "          pressure. This stall type represents about 60.0% of the total average of 33.6 cycles between issuing two      \n",
      "          instructions.                                                                                                 \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    INF   Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on         \n",
      "          sampling data. The Kernel Profiling Guide                                                                     \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details    \n",
      "          on each stall reason.                                                                                         \n",
      "\n",
      "    Section: Instruction Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Avg. Executed Instructions Per Scheduler        inst   121,395.20\n",
      "    Executed Instructions                           inst   19,423,232\n",
      "    Avg. Issued Instructions Per Scheduler          inst   121,443.20\n",
      "    Issued Instructions                             inst   19,430,912\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   256\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  1,024\n",
      "    Registers Per Thread             register/thread              36\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block       Kbyte/block            2.05\n",
      "    # SMs                                         SM              40\n",
      "    Threads                                   thread         262,144\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                                6.40\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            6\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            4\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        94.75\n",
      "    Achieved Active Warps Per SM           warp        30.32\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle       68,514\n",
      "    Total DRAM Elapsed Cycles        cycle   37,511,168\n",
      "    Average L1 Active Cycles         cycle   538,468.93\n",
      "    Total L1 Elapsed Cycles          cycle   21,928,496\n",
      "    Average L2 Active Cycles         cycle      463,119\n",
      "    Total L2 Elapsed Cycles          cycle   24,774,656\n",
      "    Average SM Active Cycles         cycle   538,468.93\n",
      "    Total SM Elapsed Cycles          cycle   21,928,496\n",
      "    Average SMSP Active Cycles       cycle   538,355.46\n",
      "    Total SMSP Elapsed Cycles        cycle   87,713,984\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    Section: Source Counters\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Branch Instructions Ratio           %         0.01\n",
      "    Branch Instructions              inst      286,720\n",
      "    Branch Efficiency                   %          100\n",
      "    Avg. Divergent Branches                          0\n",
      "    ------------------------- ----------- ------------\n",
      "\n",
      "\n",
      "[2] Nsight Compute details page for vec_add_opt\n",
      "[2088] vec_add_opt@127.0.0.1\n",
      "  vec_add_kernel(const float *, const float *, float *, int) (4096, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ----------- ------------\n",
      "    Metric Name             Metric Unit Metric Value\n",
      "    ----------------------- ----------- ------------\n",
      "    DRAM Frequency                  Ghz         4.71\n",
      "    SM Frequency                    Mhz       584.43\n",
      "    Elapsed Cycles                cycle       31,463\n",
      "    Memory Throughput                 %        84.05\n",
      "    DRAM Throughput                   %        84.05\n",
      "    Duration                         us        53.82\n",
      "    L1/TEX Cache Throughput           %        29.52\n",
      "    L2 Cache Throughput               %        28.22\n",
      "    SM Active Cycles              cycle    28,445.47\n",
      "    Compute (SM) Throughput           %        36.39\n",
      "    ----------------------- ----------- ------------\n",
      "\n",
      "    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   \n",
      "          further improve performance, work will likely need to be shifted from the most utilized to another unit.      \n",
      "          Start by analyzing DRAM in the Memory Workload Analysis section.                                              \n",
      "\n",
      "    Section: GPU Speed Of Light Roofline Chart\n",
      "    INF   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       \n",
      "          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel        \n",
      "          Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details  \n",
      "          on roofline analysis.                                                                                         \n",
      "\n",
      "    Section: PM Sampling\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Maximum Buffer Size             Kbyte       262.14\n",
      "    Dropped Samples                sample            0\n",
      "    Maximum Sampling Interval       cycle       20,000\n",
      "    # Pass Groups                                    1\n",
      "    ------------------------- ----------- ------------\n",
      "\n",
      "    Section: Compute Workload Analysis\n",
      "    -------------------- ----------- ------------\n",
      "    Metric Name          Metric Unit Metric Value\n",
      "    -------------------- ----------- ------------\n",
      "    Executed Ipc Active   inst/cycle         1.53\n",
      "    Executed Ipc Elapsed  inst/cycle         1.45\n",
      "    Issue Slots Busy               %        38.24\n",
      "    Issued Ipc Active     inst/cycle         1.53\n",
      "    SM Busy                        %        38.24\n",
      "    -------------------- ----------- ------------\n",
      "\n",
      "    INF   FMA is the highest-utilized pipeline (27.4%) based on active cycles, taking into account the rates of its     \n",
      "          different instructions. It executes 32-bit floating point (FADD, FMUL, FMAD, ...) and integer (IMUL, IMAD)    \n",
      "          operations. It is well-utilized, but should not be a bottleneck.                                              \n",
      "\n",
      "    Section: Memory Workload Analysis\n",
      "    ----------------- ----------- ------------\n",
      "    Metric Name       Metric Unit Metric Value\n",
      "    ----------------- ----------- ------------\n",
      "    Memory Throughput     Gbyte/s       253.30\n",
      "    Mem Busy                    %        28.22\n",
      "    Max Bandwidth               %        84.05\n",
      "    L1/TEX Hit Rate             %            0\n",
      "    L2 Hit Rate                 %        33.61\n",
      "    Mem Pipes Busy              %        21.92\n",
      "    ----------------- ----------- ------------\n",
      "\n",
      "    Section: Memory Workload Analysis Chart\n",
      "    WRN   The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an  \n",
      "          additional metric could enable the rule to provide more guidance.                                             \n",
      "\n",
      "    Section: Scheduler Statistics\n",
      "    ---------------------------- ----------- ------------\n",
      "    Metric Name                  Metric Unit Metric Value\n",
      "    ---------------------------- ----------- ------------\n",
      "    One or More Eligible                   %        38.19\n",
      "    Issued Warp Per Scheduler                        0.38\n",
      "    No Eligible                            %        61.81\n",
      "    Active Warps Per Scheduler          warp         6.34\n",
      "    Eligible Warps Per Scheduler        warp         0.57\n",
      "    ---------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 15.95%                                                                                    \n",
      "          Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      \n",
      "          issues an instruction every 2.6 cycles. This might leave hardware resources underutilized and may lead to     \n",
      "          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    \n",
      "          6.34 active warps per scheduler, but only an average of 0.57 warps were eligible per cycle. Eligible warps    \n",
      "          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   \n",
      "          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      \n",
      "          eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp  \n",
      "          State Statistics and Source Counters sections.                                                                \n",
      "\n",
      "    Section: Warp State Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Warp Cycles Per Issued Instruction             cycle        16.61\n",
      "    Warp Cycles Per Executed Instruction           cycle        16.65\n",
      "    Avg. Active Threads Per Warp                                   32\n",
      "    Avg. Not Predicated Off Threads Per Warp                    27.77\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 15.95%                                                                                          \n",
      "          On average, each warp of this kernel spends 9.0 cycles being stalled waiting for a scoreboard dependency on a \n",
      "          L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon  \n",
      "          to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory      \n",
      "          access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing    \n",
      "          data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to   \n",
      "          shared memory. This stall type represents about 54.4% of the total average of 16.6 cycles between issuing     \n",
      "          two instructions.                                                                                             \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    INF   Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on         \n",
      "          sampling data. The Kernel Profiling Guide                                                                     \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details    \n",
      "          on each stall reason.                                                                                         \n",
      "\n",
      "    Section: Instruction Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Avg. Executed Instructions Per Scheduler        inst    10,854.40\n",
      "    Executed Instructions                           inst    1,736,704\n",
      "    Avg. Issued Instructions Per Scheduler          inst    10,878.40\n",
      "    Issued Instructions                             inst    1,740,544\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 13.68%                                                                                          \n",
      "          This kernel executes 0 fused and 32768 non-fused FP32 instructions. By converting pairs of non-fused          \n",
      "          instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point),           \n",
      "          higher-throughput equivalent, the achieved FP32 performance could be increased by up to 50% (relative to its  \n",
      "          current performance). Check the Source page to identify where this kernel executes FP32 instructions.         \n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   256\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  4,096\n",
      "    Registers Per Thread             register/thread              30\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM              40\n",
      "    Threads                                   thread       1,048,576\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                               25.60\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block            8\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            4\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        81.37\n",
      "    Achieved Active Warps Per SM           warp        26.04\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 15.95%                                                                                          \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (81.4%) can be the     \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle      213,025\n",
      "    Total DRAM Elapsed Cycles        cycle    2,027,520\n",
      "    Average L1 Active Cycles         cycle    28,445.47\n",
      "    Total L1 Elapsed Cycles          cycle    1,195,760\n",
      "    Average L2 Active Cycles         cycle    38,469.62\n",
      "    Total L2 Elapsed Cycles          cycle    1,399,712\n",
      "    Average SM Active Cycles         cycle    28,445.47\n",
      "    Total SM Elapsed Cycles          cycle    1,195,760\n",
      "    Average SMSP Active Cycles       cycle    28,481.66\n",
      "    Total SMSP Elapsed Cycles        cycle    4,783,040\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    Section: Source Counters\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Branch Instructions Ratio           %         0.09\n",
      "    Branch Instructions              inst      163,840\n",
      "    Branch Efficiency                   %          100\n",
      "    Avg. Divergent Branches                          0\n",
      "    ------------------------- ----------- ------------\n",
      "\n",
      "\n",
      "[2] Nsight Compute details page for reduce_naive_add\n",
      "[2191] reduce_naive_add@127.0.0.1\n",
      "  naive_add(const float *, float *, int) (4096, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
      "    Section: GPU Speed Of Light Throughput\n",
      "    ----------------------- ----------- ------------\n",
      "    Metric Name             Metric Unit Metric Value\n",
      "    ----------------------- ----------- ------------\n",
      "    DRAM Frequency                  Ghz         5.00\n",
      "    SM Frequency                    Mhz       584.99\n",
      "    Elapsed Cycles                cycle    2,232,813\n",
      "    Memory Throughput                 %         2.42\n",
      "    DRAM Throughput                   %         0.55\n",
      "    Duration                         ms         3.82\n",
      "    L1/TEX Cache Throughput           %         4.85\n",
      "    L2 Cache Throughput               %         2.06\n",
      "    SM Active Cycles              cycle 2,227,024.65\n",
      "    Compute (SM) Throughput           %         1.17\n",
      "    ----------------------- ----------- ------------\n",
      "\n",
      "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
      "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
      "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
      "\n",
      "    Section: GPU Speed Of Light Roofline Chart\n",
      "    INF   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of \n",
      "          this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide       \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline      \n",
      "          analysis.                                                                                                     \n",
      "\n",
      "    Section: PM Sampling\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Maximum Buffer Size             Mbyte         1.05\n",
      "    Dropped Samples                sample            0\n",
      "    Maximum Sampling Interval       cycle       20,000\n",
      "    # Pass Groups                                    1\n",
      "    ------------------------- ----------- ------------\n",
      "\n",
      "    Section: Compute Workload Analysis\n",
      "    -------------------- ----------- ------------\n",
      "    Metric Name          Metric Unit Metric Value\n",
      "    -------------------- ----------- ------------\n",
      "    Executed Ipc Active   inst/cycle         0.00\n",
      "    Executed Ipc Elapsed  inst/cycle         0.00\n",
      "    Issue Slots Busy               %         0.11\n",
      "    Issued Ipc Active     inst/cycle         0.00\n",
      "    SM Busy                        %         0.11\n",
      "    -------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 99.94%                                                                                    \n",
      "          All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps   \n",
      "          per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.             \n",
      "\n",
      "    Section: Memory Workload Analysis\n",
      "    ----------------- ----------- ------------\n",
      "    Metric Name       Metric Unit Metric Value\n",
      "    ----------------- ----------- ------------\n",
      "    Memory Throughput     Gbyte/s         1.74\n",
      "    Mem Busy                    %         2.42\n",
      "    Max Bandwidth               %         1.32\n",
      "    L1/TEX Hit Rate             %            0\n",
      "    L2 Hit Rate                 %        88.82\n",
      "    Mem Pipes Busy              %         1.17\n",
      "    ----------------- ----------- ------------\n",
      "\n",
      "    Section: Memory Workload Analysis Chart\n",
      "    WRN   The optional metric lts__average_gcomp_input_sector_success_rate.pct could not be found. Collecting it as an  \n",
      "          additional metric could enable the rule to provide more guidance.                                             \n",
      "\n",
      "    Section: Scheduler Statistics\n",
      "    ---------------------------- ----------- ------------\n",
      "    Metric Name                  Metric Unit Metric Value\n",
      "    ---------------------------- ----------- ------------\n",
      "    One or More Eligible                   %         0.11\n",
      "    Issued Warp Per Scheduler                        0.00\n",
      "    No Eligible                            %        99.89\n",
      "    Active Warps Per Scheduler          warp         6.74\n",
      "    Eligible Warps Per Scheduler        warp         0.00\n",
      "    ---------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Local Speedup: 97.58%                                                                                    \n",
      "          Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      \n",
      "          issues an instruction every 895.7 cycles. This might leave hardware resources underutilized and may lead to   \n",
      "          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    \n",
      "          6.74 active warps per scheduler, but only an average of 0.00 warps were eligible per cycle. Eligible warps    \n",
      "          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   \n",
      "          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      \n",
      "          eligible warps, avoid possible load imbalances due to highly different execution durations per warp.          \n",
      "          Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.            \n",
      "\n",
      "    Section: Warp State Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Warp Cycles Per Issued Instruction             cycle     6,039.92\n",
      "    Warp Cycles Per Executed Instruction           cycle     6,098.90\n",
      "    Avg. Active Threads Per Warp                                   32\n",
      "    Avg. Not Predicated Off Threads Per Warp                    29.33\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 41.45%                                                                                          \n",
      "          On average, each warp of this kernel spends 2503.8 cycles being stalled after EXIT waiting for all            \n",
      "          outstanding memory operations to complete so that warp's resources can be freed. A high number of stalls due  \n",
      "          to draining warps typically occurs when a lot of data is written to memory towards the end of a kernel. Make  \n",
      "          sure the memory access patterns of these store operations are optimal for the target architecture and         \n",
      "          consider parallelized data reduction, if applicable. This stall type represents about 41.5% of the total      \n",
      "          average of 6039.9 cycles between issuing two instructions.                                                    \n",
      "    ----- --------------------------------------------------------------------------------------------------------------\n",
      "    INF   Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on         \n",
      "          sampling data. The Kernel Profiling Guide                                                                     \n",
      "          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details    \n",
      "          on each stall reason.                                                                                         \n",
      "\n",
      "    Section: Instruction Statistics\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Metric Name                              Metric Unit Metric Value\n",
      "    ---------------------------------------- ----------- ------------\n",
      "    Avg. Executed Instructions Per Scheduler        inst     2,457.60\n",
      "    Executed Instructions                           inst      393,216\n",
      "    Avg. Issued Instructions Per Scheduler          inst     2,481.60\n",
      "    Issued Instructions                             inst      397,056\n",
      "    ---------------------------------------- ----------- ------------\n",
      "\n",
      "    Section: Launch Statistics\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Metric Name                          Metric Unit    Metric Value\n",
      "    -------------------------------- --------------- ---------------\n",
      "    Block Size                                                   256\n",
      "    Function Cache Configuration                     CachePreferNone\n",
      "    Grid Size                                                  4,096\n",
      "    Registers Per Thread             register/thread              16\n",
      "    Shared Memory Configuration Size           Kbyte           32.77\n",
      "    Driver Shared Memory Per Block        byte/block               0\n",
      "    Dynamic Shared Memory Per Block       byte/block               0\n",
      "    Static Shared Memory Per Block        byte/block               0\n",
      "    # SMs                                         SM              40\n",
      "    Threads                                   thread       1,048,576\n",
      "    Uses Green Context                                             0\n",
      "    Waves Per SM                                               25.60\n",
      "    -------------------------------- --------------- ---------------\n",
      "\n",
      "    Section: Occupancy\n",
      "    ------------------------------- ----------- ------------\n",
      "    Metric Name                     Metric Unit Metric Value\n",
      "    ------------------------------- ----------- ------------\n",
      "    Block Limit SM                        block           16\n",
      "    Block Limit Registers                 block           16\n",
      "    Block Limit Shared Mem                block           16\n",
      "    Block Limit Warps                     block            4\n",
      "    Theoretical Active Warps per SM        warp           32\n",
      "    Theoretical Occupancy                     %          100\n",
      "    Achieved Occupancy                        %        83.76\n",
      "    Achieved Active Warps Per SM           warp        26.80\n",
      "    ------------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 16.24%                                                                                          \n",
      "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.8%) can be the     \n",
      "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
      "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
      "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
      "          optimizing occupancy.                                                                                         \n",
      "\n",
      "    Section: GPU and Memory Workload Distribution\n",
      "    -------------------------- ----------- ------------\n",
      "    Metric Name                Metric Unit Metric Value\n",
      "    -------------------------- ----------- ------------\n",
      "    Average DRAM Active Cycles       cycle   103,985.50\n",
      "    Total DRAM Elapsed Cycles        cycle  152,539,136\n",
      "    Average L1 Active Cycles         cycle 2,227,024.65\n",
      "    Total L1 Elapsed Cycles          cycle   89,299,096\n",
      "    Average L2 Active Cycles         cycle   214,502.78\n",
      "    Total L2 Elapsed Cycles          cycle  100,773,152\n",
      "    Average SM Active Cycles         cycle 2,227,024.65\n",
      "    Total SM Elapsed Cycles          cycle   89,299,096\n",
      "    Average SMSP Active Cycles       cycle 2,222,804.42\n",
      "    Total SMSP Elapsed Cycles        cycle  357,196,384\n",
      "    -------------------------- ----------- ------------\n",
      "\n",
      "    OPT   Est. Speedup: 6.347%                                                                                          \n",
      "          One or more L2 Slices have a much higher number of active cycles than the average number of active cycles.    \n",
      "          Maximum instance value is 93.18% above the average, while the minimum instance value is 48.32% below the      \n",
      "          average.                                                                                                      \n",
      "\n",
      "    Section: Source Counters\n",
      "    ------------------------- ----------- ------------\n",
      "    Metric Name               Metric Unit Metric Value\n",
      "    ------------------------- ----------- ------------\n",
      "    Branch Instructions Ratio           %         0.17\n",
      "    Branch Instructions              inst       65,536\n",
      "    Branch Efficiency                   %            0\n",
      "    Avg. Divergent Branches                          0\n",
      "    ------------------------- ----------- ------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------- Second loop: re-import reports and show details --------\n",
    "print(\"\\n=== Printing Nsight Compute details for each kernel ===\")\n",
    "for k in kernels:\n",
    "    print(f\"\\n[2] Nsight Compute details page for {k}\")\n",
    "    !NCU_DEFAULTS=\"\" ncu --import profiles/{k}.ncu-rep --page details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "130fb77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\tmatrix_multiplication  reduction\n",
      "CMakeLists.txt\tprofiles\t       test_colab_server.ipynb\n",
      "include\t\tREADME.md\t       vector_add\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97fd7bb",
   "metadata": {},
   "source": [
    "# Create a Zip File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a81cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Adjust this if your repo root is different\n",
    "# repo_root = \"/content/GPU_mode\"\n",
    "# profiles_dir = os.path.join(repo_root, \"profiles\")\n",
    "\n",
    "# # Make sure the profiles folder exists\n",
    "# if os.path.isdir(profiles_dir):\n",
    "#     # Create profiles.zip next to the repo root\n",
    "#     zip_path = os.path.join(repo_root, \"profiles\")\n",
    "#     shutil.make_archive(zip_path, \"zip\", profiles_dir)\n",
    "#     print(f\"Created ZIP: {zip_path}.zip\")\n",
    "# else:\n",
    "#     print(f\"No profiles folder found at: {profiles_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c331104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ZIP: /content/GPU_mode/profiles_20251202_111330.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "repo_root = \"/content/GPU_mode\"\n",
    "profiles_dir = os.path.join(repo_root, \"profiles\")\n",
    "\n",
    "# Make timestamped name\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_basename = f\"profiles_{timestamp}\"             # without .zip\n",
    "zip_path = os.path.join(repo_root, zip_basename)   # /content/GPU_mode/profiles_YYYYMMDD_HHMMSS\n",
    "\n",
    "if os.path.isdir(profiles_dir):\n",
    "    # Create /content/GPU_mode/profiles_YYYYMMDD_HHMMSS.zip\n",
    "    shutil.make_archive(zip_path, \"zip\", profiles_dir)\n",
    "    zip_file = zip_path + \".zip\"\n",
    "    print(f\"Created ZIP: {zip_file}\")\n",
    "else:\n",
    "    print(f\"No profiles folder found at: {profiles_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18d3a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\t       profiles\t\t\t     test_colab_server.ipynb\n",
      "CMakeLists.txt\t       profiles_20251202_111330.zip  vector_add\n",
      "include\t\t       README.md\n",
      "matrix_multiplication  reduction\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1a8dbf",
   "metadata": {},
   "source": [
    "# File Downloader Widget/Workflow Provided by Colab For the Profiler Zip File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fa9706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anywidget\n",
    "import traitlets\n",
    "import os\n",
    "import base64\n",
    "import mimetypes\n",
    "\n",
    "class FileDownloader(anywidget.AnyWidget):\n",
    "    \"\"\"\n",
    "    An anywidget that renders a button. When clicked, it triggers a server-side\n",
    "    read of 'file_path' and sends the content to the browser for download.\n",
    "\n",
    "    The button starts disabled and only enables after a successful handshake\n",
    "    with the Python kernel, ensuring it doesn't appear active in a dead notebook.\n",
    "    \"\"\"\n",
    "\n",
    "    # The path to the file on the server/local disk that you want to download\n",
    "    file_path = traitlets.Unicode(help=\"Path to the file to be downloaded\").tag(sync=True)\n",
    "\n",
    "    # Label for the button\n",
    "    button_text = traitlets.Unicode(\"Download File\").tag(sync=True)\n",
    "\n",
    "    _esm = \"\"\"\n",
    "    export function render({ model, el }) {\n",
    "      // Create the button element\n",
    "      let btn = document.createElement(\"button\");\n",
    "      btn.classList.add(\"jupyter-widgets\", \"jupyter-button\", \"widget-button\");\n",
    "      btn.style.width = \"100%\";\n",
    "\n",
    "      // Initial state: Disabled and waiting\n",
    "      btn.innerText = \"Waiting for Kernel...\";\n",
    "      btn.disabled = true;\n",
    "\n",
    "      // Update button text if the Python trait changes\n",
    "      model.on(\"change:button_text\", () => {\n",
    "        // Only update visually if we are already connected/enabled\n",
    "        if (!btn.disabled) {\n",
    "            btn.innerText = model.get(\"button_text\");\n",
    "        }\n",
    "      });\n",
    "\n",
    "      // Handle the click event\n",
    "      btn.addEventListener(\"click\", () => {\n",
    "        const filePath = model.get(\"file_path\");\n",
    "\n",
    "        if (!filePath) {\n",
    "            alert(\"No file path set in the Python widget!\");\n",
    "            return;\n",
    "        }\n",
    "\n",
    "        // Disable button and show loading state\n",
    "        const originalText = btn.innerText;\n",
    "        btn.innerText = \"Downloading...\";\n",
    "        btn.disabled = true;\n",
    "\n",
    "        // Send a request message to the Python backend\n",
    "        model.send({ type: \"request_download\" });\n",
    "\n",
    "        // Helper to restore button state\n",
    "        const restoreBtn = () => {\n",
    "            btn.innerText = originalText;\n",
    "            btn.disabled = false;\n",
    "        };\n",
    "\n",
    "        // Timeout safety to restore button if Python doesn't respond within 5s\n",
    "        setTimeout(restoreBtn, 5000);\n",
    "      });\n",
    "\n",
    "      el.appendChild(btn);\n",
    "\n",
    "      // Listen for messages coming from Python\n",
    "      model.on(\"msg:custom\", (msg) => {\n",
    "        if (msg.type === \"connection_verified\") {\n",
    "            // HANDSHAKE COMPLETE: Kernel is alive.\n",
    "            btn.disabled = false;\n",
    "            btn.innerText = model.get(\"button_text\");\n",
    "        }\n",
    "        else if (msg.type === \"file_content\") {\n",
    "            // 1. Create a Blob from the Base64 data\n",
    "            const byteCharacters = atob(msg.content);\n",
    "            const byteNumbers = new Array(byteCharacters.length);\n",
    "            for (let i = 0; i < byteCharacters.length; i++) {\n",
    "                byteNumbers[i] = byteCharacters.charCodeAt(i);\n",
    "            }\n",
    "            const byteArray = new Uint8Array(byteNumbers);\n",
    "            const blob = new Blob([byteArray], { type: msg.mime_type });\n",
    "\n",
    "            // 2. Create a temporary link to trigger the download\n",
    "            const url = window.URL.createObjectURL(blob);\n",
    "            const a = document.createElement(\"a\");\n",
    "            a.style.display = \"none\";\n",
    "            a.href = url;\n",
    "            a.download = msg.filename;\n",
    "            document.body.appendChild(a);\n",
    "            a.click();\n",
    "\n",
    "            // 3. Cleanup\n",
    "            window.URL.revokeObjectURL(url);\n",
    "            document.body.removeChild(a);\n",
    "\n",
    "            // Restore button text\n",
    "            btn.innerText = model.get(\"button_text\");\n",
    "            btn.disabled = false;\n",
    "\n",
    "        } else if (msg.type === \"error\") {\n",
    "            alert(`Error: ${msg.message}`);\n",
    "            btn.innerText = model.get(\"button_text\");\n",
    "            btn.disabled = false;\n",
    "        }\n",
    "      });\n",
    "\n",
    "      // INITIATE HANDSHAKE\n",
    "      // Send a message to Python to check if the kernel is listening.\n",
    "      // If the kernel is dead (saved notebook), this message goes nowhere,\n",
    "      // and the button remains disabled.\n",
    "      setTimeout(() => {\n",
    "        model.send({ type: \"check_connection\" });\n",
    "      }, 500);\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_path=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if file_path:\n",
    "            self.file_path = file_path\n",
    "\n",
    "        # Register the message handler\n",
    "        self.on_msg(self._handle_custom_msg)\n",
    "\n",
    "    def _handle_custom_msg(self, msg, content):\n",
    "        \"\"\"\n",
    "        Callback for when the frontend sends a message to Python.\n",
    "        \"\"\"\n",
    "        msg_type = msg.get(\"type\")\n",
    "\n",
    "        if msg_type == \"check_connection\":\n",
    "            # Reply to the frontend to confirm we are alive\n",
    "            self.send({\"type\": \"connection_verified\"})\n",
    "\n",
    "        elif msg_type == \"request_download\":\n",
    "            self._process_download()\n",
    "\n",
    "    def _process_download(self):\n",
    "        \"\"\"\n",
    "        Reads the file from disk and sends it to the frontend.\n",
    "        \"\"\"\n",
    "        target_path = self.file_path\n",
    "\n",
    "        # Basic validation\n",
    "        if not target_path:\n",
    "            self.send({\"type\": \"error\", \"message\": \"File path is not defined.\"})\n",
    "            return\n",
    "\n",
    "        if not os.path.exists(target_path):\n",
    "            self.send({\"type\": \"error\", \"message\": f\"File not found: {target_path}\"})\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Guess the MIME type so the browser handles it correctly\n",
    "            mime_type, _ = mimetypes.guess_type(target_path)\n",
    "            if mime_type is None:\n",
    "                mime_type = 'application/octet-stream'\n",
    "\n",
    "            # Read and encode the file\n",
    "            with open(target_path, \"rb\") as f:\n",
    "                file_content = f.read()\n",
    "\n",
    "            b64_content = base64.b64encode(file_content).decode(\"utf-8\")\n",
    "\n",
    "            # Send back to JS\n",
    "            self.send({\n",
    "                \"type\": \"file_content\",\n",
    "                \"filename\": os.path.basename(target_path),\n",
    "                \"mime_type\": mime_type,\n",
    "                \"content\": b64_content\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            self.send({\"type\": \"error\", \"message\": str(e)})\n",
    "\n",
    "# dummy_filename = \"example_data.txt\"\n",
    "# with open(dummy_filename, \"w\") as f:\n",
    "#     f.write(\"Hello! This is a file dynamically read from the kernel disk.\\n\")\n",
    "#     f.write(\"If you are reading this, the widget worked.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d35434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/GPU_mode/profiles_20251202_111330.zip\n"
     ]
    }
   ],
   "source": [
    "print(zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fcb143e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\t       profiles\t\t\t     test_colab_server.ipynb\n",
      "CMakeLists.txt\t       profiles_20251202_111330.zip  vector_add\n",
      "include\t\t       README.md\n",
      "matrix_multiplication  reduction\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81de5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0154a8fd25344f596c6521625d8efeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "<__main__.FileDownloader object at 0x7f4246627ad0>"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the timestamped zip with FileDownloader - Used to Download the profiles zip folder\n",
    "# FileDownloader(file_path=zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e135d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import FileLink\n",
    "\n",
    "# zip_path = \"/content/GPU_mode/profiles_run_2025-11-28T19-12-00.zip\"\n",
    "# FileLink(zip_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8963a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

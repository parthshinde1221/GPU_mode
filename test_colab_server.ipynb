{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a74495ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Colab GPU available:\", torch.cuda.is_available())\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c503bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 29 02:48:52 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c5c53e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\t       profiles\t\t\t     test_colab_server.ipynb\n",
      "CMakeLists.txt\t       profiles_20251129_024337.zip  vector_add\n",
      "include\t\t       README.md\n",
      "matrix_multiplication  reduction\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40c22393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmake version 3.31.10\n",
      "\n",
      "CMake suite maintained and supported by Kitware (kitware.com/cmake).\n"
     ]
    }
   ],
   "source": [
    "!cmake --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ed1ef",
   "metadata": {},
   "source": [
    "# Run from here always after any change in git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5b2d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca45e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631aa11b",
   "metadata": {},
   "source": [
    "# Make a new clone from the git repo and then run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38e856e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'GPU_mode'...\n",
      "remote: Enumerating objects: 62, done.\u001b[K\n",
      "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
      "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
      "remote: Total 62 (delta 25), reused 49 (delta 12), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (62/62), 25.98 KiB | 12.99 MiB/s, done.\n",
      "Resolving deltas: 100% (25/25), done.\n",
      "/content/GPU_mode\n",
      "CMakeLists.txt\tmatrix_multiplication  reduction\t\tvector_add\n",
      "include\t\tREADME.md\t       test_colab_server.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Always start from /content\n",
    "%cd /content\n",
    "\n",
    "# Remove any old copies so paths don't get nested\n",
    "!rm -rf GPU_mode\n",
    "\n",
    "# Clone your repo (note the exact repo name in the URL)\n",
    "!git clone https://github.com/parthshinde1221/GPU_mode.git\n",
    "\n",
    "# Enter the repo root\n",
    "%cd GPU_mode\n",
    "\n",
    "# Sanity check: you MUST see CMakeLists.txt here\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f875e",
   "metadata": {},
   "source": [
    "# Building all CUDA kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfcc1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The CXX compiler identification is GNU 11.4.0\n",
      "-- The CUDA compiler identification is NVIDIA 12.5.82 with host compiler GNU 11.4.0\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Detecting CUDA compiler ABI info\n",
      "-- Detecting CUDA compiler ABI info - done\n",
      "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
      "-- Detecting CUDA compile features\n",
      "-- Detecting CUDA compile features - done\n",
      "-- Adding matmul target: matmul_naive from /content/GPU_mode/matrix_multiplication/matmul_naive.cu\n",
      "-- Adding matmul target: matmul_tiled from /content/GPU_mode/matrix_multiplication/matmul_tiled.cu\n",
      "-- Adding vec_add target: vec_add_naive from /content/GPU_mode/vector_add/vec_add_naive.cu\n",
      "-- Adding vec_add target: vec_add_opt from /content/GPU_mode/vector_add/vec_add_opt.cu\n",
      "-- Adding reduction target: reduce_naive_add from /content/GPU_mode/reduction/reduce_naive_add.cu\n",
      "-- Adding reduction target: reduce_optimized_add from /content/GPU_mode/reduction/reduce_optimized_add.cu\n",
      "-- Configuring done (2.8s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /content/GPU_mode/build\n",
      "[  5%] \u001b[32mBuilding CUDA object vector_add/CMakeFiles/vec_add_naive.dir/vec_add_naive.cu.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CUDA object matrix_multiplication/CMakeFiles/matmul_tiled.dir/matmul_tiled.cu.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CUDA object matrix_multiplication/CMakeFiles/matmul_naive.dir/matmul_naive.cu.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding CUDA object vector_add/CMakeFiles/vec_add_opt.dir/vec_add_opt.cu.o\u001b[0m\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/matrix_multiplication/matmul_naive.cu(10)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"sum\"\u001b[0m was declared but never referenced\n",
      "          float sum = 0.0f;\n",
      "                ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/matrix_multiplication/matmul_naive.cu(10)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"sum\"\u001b[0m was declared but never referenced\n",
      "          float sum = 0.0f;\n",
      "                ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/matrix_multiplication/matmul_naive.cu(10)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"sum\"\u001b[0m was declared but never referenced\n",
      "          float sum = 0.0f;\n",
      "                ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/matrix_multiplication/matmul_naive.cu(10)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"sum\"\u001b[0m was declared but never referenced\n",
      "          float sum = 0.0f;\n",
      "                ^\n",
      "\n",
      "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
      "\n",
      "[ 27%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/vec_add_naive.dir/cmake_device_link.o\u001b[0m\n",
      "[ 33%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/vec_add_opt.dir/cmake_device_link.o\u001b[0m\n",
      "[ 38%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/vec_add_opt\u001b[0m\n",
      "[ 44%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/vec_add_naive\u001b[0m\n",
      "[ 44%] Built target vec_add_naive\n",
      "[ 50%] \u001b[32mBuilding CUDA object reduction/CMakeFiles/reduce_naive_add.dir/reduce_naive_add.cu.o\u001b[0m\n",
      "[ 50%] Built target vec_add_opt\n",
      "[ 55%] \u001b[32mBuilding CUDA object reduction/CMakeFiles/reduce_optimized_add.dir/reduce_optimized_add.cu.o\u001b[0m\n",
      "[ 61%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/matmul_tiled.dir/cmake_device_link.o\u001b[0m\n",
      "[ 66%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/matmul_naive.dir/cmake_device_link.o\u001b[0m\n",
      "[ 72%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/matmul_tiled\u001b[0m\n",
      "[ 77%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/matmul_naive\u001b[0m\n",
      "[ 77%] Built target matmul_tiled\n",
      "[ 77%] Built target matmul_naive\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(16)\u001b[0m: \u001b[01;31merror\u001b[0m: no instance of overloaded function \u001b[01m\"atomicAdd\"\u001b[0m matches the argument list\n",
      "            argument types are: (float, float)\n",
      "                                      idx,input,output,atomicAdd(output,input[idx]));\n",
      "                                                       ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/usr/local/cuda/bin/../targets/x86_64-linux/include/crt/sm_90_rt.h(112)\u001b[0m: \u001b[01;36mnote\u001b[0m #3326-D: function \u001b[01m\"atomicAdd(float4 *, float4)\"\u001b[0m does not match because argument #1 does not match parameter\n",
      "  static __attribute__((device)) __inline__ float4 atomicAdd(float4 *__address, float4 val) { }\n",
      "                                                   ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/usr/local/cuda/bin/../targets/x86_64-linux/include/crt/sm_90_rt.h(109)\u001b[0m: \u001b[01;36mnote\u001b[0m #3326-D: function \u001b[01m\"atomicAdd(float2 *, float2)\"\u001b[0m does not match because argument #1 does not match parameter\n",
      "  static __attribute__((device)) __inline__ float2 atomicAdd(float2 *__address, float2 val) { }\n",
      "                                                   ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/usr/local/cuda/bin/../targets/x86_64-linux/include/sm_60_atomic_functions.h(93)\u001b[0m: \u001b[01;36mnote\u001b[0m #3326-D: function \u001b[01m\"atomicAdd(double *, double)\"\u001b[0m does not match because argument #1 does not match parameter\n",
      "  static __inline__ __attribute__((device)) double atomicAdd(double *address, double val) { }\n",
      "                                                   ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/usr/local/cuda/bin/../targets/x86_64-linux/include/sm_20_atomic_functions.h(88)\u001b[0m: \u001b[01;36mnote\u001b[0m #3326-D: function \u001b[01m\"atomicAdd(float *, float)\"\u001b[0m does not match because argument #1 does not match parameter\n",
      "  static __inline__ __attribute__((device)) float atomicAdd(float *address, float val) { }\n",
      "                                                  ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/usr/local/cuda/bin/../targets/x86_64-linux/include/device_atomic_functions.h(169)\u001b[0m: \u001b[01;36mnote\u001b[0m #3326-D: function \u001b[01m\"atomicAdd(unsigned long long *, unsigned long long)\"\u001b[0m does not match because argument #1 does not match parameter\n",
      "  static __inline__ __attribute__((device)) unsigned long long int atomicAdd(unsigned long long int *address, unsigned long long int val) { }\n",
      "                                                                   ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/usr/local/cuda/bin/../targets/x86_64-linux/include/device_atomic_functions.h(91)\u001b[0m: \u001b[01;36mnote\u001b[0m #3326-D: function \u001b[01m\"atomicAdd(unsigned int *, unsigned int)\"\u001b[0m does not match because argument #1 does not match parameter\n",
      "  static __inline__ __attribute__((device)) unsigned int atomicAdd(unsigned int *address, unsigned int val) { }\n",
      "                                                         ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/usr/local/cuda/bin/../targets/x86_64-linux/include/device_atomic_functions.h(89)\u001b[0m: \u001b[01;36mnote\u001b[0m #3326-D: function \u001b[01m\"atomicAdd(int *, int)\"\u001b[0m does not match because argument #1 does not match parameter\n",
      "  static __inline__ __attribute__((device)) int atomicAdd(int *address, int val) { }\n",
      "                                                ^\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(44)\u001b[0m: \u001b[01;31merror\u001b[0m: no instance of overloaded function \u001b[01m\"cudaMalloc\"\u001b[0m matches the argument list\n",
      "            argument types are: (float *, const size_t)\n",
      "      do { cudaError_t _err = (cudaMalloc(d_input,bytes)); if (_err != cudaSuccess) { fprintf(\n",
      "                               ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime_api.h(5363)\u001b[0m: \u001b[01;36mnote\u001b[0m #3326-D: function \u001b[01m\"cudaMalloc(void **, size_t)\"\u001b[0m does not match because argument #1 does not match parameter\n",
      "  extern __attribute__((host)) __attribute__((cudart_builtin)) cudaError_t cudaMalloc(void **devPtr, size_t size);\n",
      "                                                                           ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime.h(761)\u001b[0m: \u001b[01;36mnote\u001b[0m #3327-D: candidate function template \u001b[01m\"cudaMalloc(T **, size_t)\"\u001b[0m failed deduction\n",
      "  static __inline__ __attribute__((host)) cudaError_t cudaMalloc(\n",
      "                                                      ^\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(45)\u001b[0m: \u001b[01;31merror\u001b[0m: no instance of overloaded function \u001b[01m\"cudaMalloc\"\u001b[0m matches the argument list\n",
      "            argument types are: (float *, const size_t)\n",
      "      do { cudaError_t _err = (cudaMalloc(d_input,bytes)); if (_err != cudaSuccess) { fprintf(\n",
      "                               ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime_api.h(5363)\u001b[0m: \u001b[01;36mnote\u001b[0m #3326-D: function \u001b[01m\"cudaMalloc(void **, size_t)\"\u001b[0m does not match because argument #1 does not match parameter\n",
      "  extern __attribute__((host)) __attribute__((cudart_builtin)) cudaError_t cudaMalloc(void **devPtr, size_t size);\n",
      "                                                                           ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime.h(761)\u001b[0m: \u001b[01;36mnote\u001b[0m #3327-D: candidate function template \u001b[01m\"cudaMalloc(T **, size_t)\"\u001b[0m failed deduction\n",
      "  static __inline__ __attribute__((host)) cudaError_t cudaMalloc(\n",
      "                                                      ^\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(48)\u001b[0m: \u001b[01;31merror\u001b[0m: identifier \"\u001b[01mh_input\u001b[0m\" is undefined\n",
      "      do { cudaError_t _err = (cudaMemcpy(d_input,h_input.data(),bytes,cudaMemcpyHostToDevice)); if (_err != cudaSuccess) { fprintf(\n",
      "                                                  ^\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(51)\u001b[0m: \u001b[01;31merror\u001b[0m: argument of type \"float\" is incompatible with parameter of type \"void *\"\n",
      "      do { cudaError_t _err = (cudaMemset(d_output,0.0f,bytes)); if (_err != cudaSuccess) { fprintf(\n",
      "                                          ^\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(54)\u001b[0m: \u001b[01;31merror\u001b[0m: no operator \"\u001b[01m+\u001b[0m\" matches these operands\n",
      "            operand types are: const int + dim3\n",
      "      dim3 gridSize = (N + blockSize - 1) / blockSize;\n",
      "                         ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(54)\u001b[0m: \u001b[01;36mnote\u001b[0m #3328-D: built-in operator+(<promoted arithmetic>, <promoted arithmetic>) does not match because argument #2 does not match parameter\n",
      "      dim3 gridSize = (N + blockSize - 1) / blockSize;\n",
      "                         ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(54)\u001b[0m: \u001b[01;36mnote\u001b[0m #3328-D: built-in operator+(<pointer to object>, <ptrdiff_t>) does not match because argument #1 does not match parameter\n",
      "      dim3 gridSize = (N + blockSize - 1) / blockSize;\n",
      "                         ^\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(54)\u001b[0m: \u001b[01;36mnote\u001b[0m #3328-D: built-in operator+(<ptrdiff_t>, <pointer to object>) does not match because argument #2 does not match parameter\n",
      "      dim3 gridSize = (N + blockSize - 1) / blockSize;\n",
      "                         ^\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(60)\u001b[0m: \u001b[01;31merror\u001b[0m: identifier \"\u001b[01mcout\u001b[0m\" is undefined\n",
      "      cout << d_output;\n",
      "      ^\n",
      "\n",
      "\u001b[01m\u001b[0m\u001b[01m/content/GPU_mode/reduction/reduce_naive_add.cu(62)\u001b[0m: \u001b[01;31merror\u001b[0m: argument of type \"float\" is incompatible with parameter of type \"void *\"\n",
      "      cudaFree(d_output);\n",
      "               ^\n",
      "\n",
      "8 errors detected in the compilation of \"/content/GPU_mode/reduction/reduce_naive_add.cu\".\n",
      "gmake[2]: *** [reduction/CMakeFiles/reduce_naive_add.dir/build.make:80: reduction/CMakeFiles/reduce_naive_add.dir/reduce_naive_add.cu.o] Error 2\n",
      "gmake[1]: *** [CMakeFiles/Makefile2:289: reduction/CMakeFiles/reduce_naive_add.dir/all] Error 2\n",
      "gmake[1]: *** Waiting for unfinished jobs....\n",
      "[ 83%] \u001b[32m\u001b[1mLinking CUDA device code CMakeFiles/reduce_optimized_add.dir/cmake_device_link.o\u001b[0m\n",
      "[ 88%] \u001b[32m\u001b[1mLinking CUDA executable ../bin/reduce_optimized_add\u001b[0m\n",
      "/usr/bin/ld: /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/Scrt1.o: in function `_start':\n",
      "(.text+0x1b): undefined reference to `main'\n",
      "collect2: error: ld returned 1 exit status\n",
      "gmake[2]: *** [reduction/CMakeFiles/reduce_optimized_add.dir/build.make:123: bin/reduce_optimized_add] Error 1\n",
      "gmake[1]: *** [CMakeFiles/Makefile2:321: reduction/CMakeFiles/reduce_optimized_add.dir/all] Error 2\n",
      "gmake: *** [Makefile:91: all] Error 2\n"
     ]
    }
   ],
   "source": [
    "# Configure the project (top-level CMakeLists.txt)\n",
    "!cmake -S . -B build -DCMAKE_BUILD_TYPE=Release\n",
    "\n",
    "# Build all targets (matmul, vec_add, etc.)\n",
    "!cmake --build build -j 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe34d054",
   "metadata": {},
   "source": [
    "# Optional build single kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0125bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernels = [\"matmul\", \"vec_add\"]  # target names from each CMakeLists.txt\n",
    "\n",
    "# for k in kernels:\n",
    "#     print(f\"\\n=== Building {k} ===\")\n",
    "#     !cmake --build build --target {k} -j 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1df4574",
   "metadata": {},
   "source": [
    "# Running all Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b33cd202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global kernels\n",
    "kernels = [\"reduce_naive_add\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d424f05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running reduce_naive_add ===\n",
      "/bin/bash: line 1: ./build/bin/reduce_naive_add: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# kernels = [\"matmul_naive\", \"vec_add_naive\",\"matmul_tiled\",\"vec_add_opt\"]  # add more later: \"softmax\", \"conv\", etc.\n",
    "\n",
    "for k in kernels:\n",
    "    print(f\"\\n=== Running {k} ===\")\n",
    "    !./build/bin/{k}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b565db",
   "metadata": {},
   "source": [
    "# CUDA MemCheck all kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a30afd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2aa92b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\tmatrix_multiplication  reduction\n",
      "CMakeLists.txt\tprofiles\t       test_colab_server.ipynb\n",
      "include\t\tREADME.md\t       vector_add\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d28f099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !which cuda-memcheck\n",
    "# !which compute-sanitizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2022c2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== compute-sanitizer (memcheck) on reduce_naive_add ===\n",
      "Saved profiles/reduce_naive_add_memcheck.txt\n",
      "========= COMPUTE-SANITIZER\n",
      "========= Target application doesn't exist or is not a valid executable\n",
      "\n",
      "=== compute-sanitizer (racecheck) on reduce_naive_add ===\n",
      "Saved profiles/reduce_naive_add_racecheck.txt\n",
      "========= COMPUTE-SANITIZER\n",
      "========= Target application doesn't exist or is not a valid executable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"profiles\", exist_ok=True)\n",
    "\n",
    "tools   = [\"memcheck\", \"racecheck\"]\n",
    "# kernels = [\"matmul_naive\", \"vec_add_naive\", \"matmul_tiled\", \"vec_add_opt\"]\n",
    "\n",
    "for k in kernels:\n",
    "    for t in tools:\n",
    "        print(f\"\\n=== compute-sanitizer ({t}) on {k} ===\")\n",
    "        log = f\"profiles/{k}_{t}.txt\"\n",
    "        !compute-sanitizer --tool {t} ./build/bin/{k} > {log} 2>&1\n",
    "        print(f\"Saved {log}\")\n",
    "        !tail -n 20 {log}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a3ad80",
   "metadata": {},
   "source": [
    "# NCU Profile each kernel all kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c77d5334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\tmatrix_multiplication  reduction\n",
      "CMakeLists.txt\tprofiles\t       test_colab_server.ipynb\n",
      "include\t\tREADME.md\t       vector_add\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a9463e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin\t\tCMakeFiles\t     Makefile\t\t    reduction\n",
      "CMakeCache.txt\tcmake_install.cmake  matrix_multiplication  vector_add\n"
     ]
    }
   ],
   "source": [
    "!ls build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae20b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_naive  matmul_tiled  vec_add_naive  vec_add_opt\n"
     ]
    }
   ],
   "source": [
    "!ls build/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3bcb975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import IFrame\n",
    "# import os\n",
    "\n",
    "# os.makedirs(\"profiles\", exist_ok=True)\n",
    "\n",
    "# kernels = [\"matmul\", \"vec_add\"]\n",
    "\n",
    "# for k in kernels:\n",
    "#     print(f\"\\n=== Profiling {k} with ncu ===\")\n",
    "#     # NCU_DEFAULTS=\"\" clears any default --export that Colab may set\n",
    "#     !NCU_DEFAULTS=\"\" ncu -f --set full --export html -o profiles/{k} ./build/bin/{k}\n",
    "#     display(IFrame(f\"profiles/{k}.html\", width=1024, height=600))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c12bad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running Nsight Compute and saving reports ===\n",
      "\n",
      "[1] Profiling reduce_naive_add with ncu ...\n",
      "==ERROR== './build/bin/reduce_naive_add' does not exist or is not an executable. Please make sure to specify the absolute path to './build/bin/reduce_naive_add' if the executable is not in the local directory.\n",
      "--> Saved report: profiles/reduce_naive_add.ncu-rep\n",
      "--> Duration for reduce_naive_add:\n",
      "\n",
      "All reports saved:\n",
      "total 8.0K\n",
      "-rw-r--r-- 1 root root 100 Nov 29 02:49 reduce_naive_add_memcheck.txt\n",
      "-rw-r--r-- 1 root root 100 Nov 29 02:49 reduce_naive_add_racecheck.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"profiles\", exist_ok=True)\n",
    "\n",
    "# kernels = [\"matmul_naive\", \"matmul_tiled\",\"vec_add_naive\",\"vec_add_opt\"]\n",
    "\n",
    "# -------- First loop: run profiling & save reports --------\n",
    "print(\"=== Running Nsight Compute and saving reports ===\")\n",
    "for k in kernels:\n",
    "    print(f\"\\n[1] Profiling {k} with ncu ...\")\n",
    "    !NCU_DEFAULTS=\"\" ncu -f --set full -o profiles/{k} ./build/bin/{k}\n",
    "    print(f\"--> Saved report: profiles/{k}.ncu-rep\")\n",
    "    \n",
    "    # Print the kernel Duration from the report\n",
    "    print(f\"--> Duration for {k}:\")\n",
    "    !NCU_DEFAULTS=\"\" ncu --import profiles/{k}.ncu-rep --page details | grep \"Duration\"\n",
    "\n",
    "print(\"\\nAll reports saved:\")\n",
    "!ls -lh profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65407218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Printing Nsight Compute details for each kernel ===\n",
      "\n",
      "[2] Nsight Compute details page for reduce_naive_add\n",
      "==ERROR== Could not open report file 'profiles/reduce_naive_add.ncu-rep'.\n"
     ]
    }
   ],
   "source": [
    "# -------- Second loop: re-import reports and show details --------\n",
    "print(\"\\n=== Printing Nsight Compute details for each kernel ===\")\n",
    "for k in kernels:\n",
    "    print(f\"\\n[2] Nsight Compute details page for {k}\")\n",
    "    !NCU_DEFAULTS=\"\" ncu --import profiles/{k}.ncu-rep --page details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "130fb77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\tmatrix_multiplication  reduction\n",
      "CMakeLists.txt\tprofiles\t       test_colab_server.ipynb\n",
      "include\t\tREADME.md\t       vector_add\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97fd7bb",
   "metadata": {},
   "source": [
    "# Create a Zip File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a81cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Adjust this if your repo root is different\n",
    "# repo_root = \"/content/GPU_mode\"\n",
    "# profiles_dir = os.path.join(repo_root, \"profiles\")\n",
    "\n",
    "# # Make sure the profiles folder exists\n",
    "# if os.path.isdir(profiles_dir):\n",
    "#     # Create profiles.zip next to the repo root\n",
    "#     zip_path = os.path.join(repo_root, \"profiles\")\n",
    "#     shutil.make_archive(zip_path, \"zip\", profiles_dir)\n",
    "#     print(f\"Created ZIP: {zip_path}.zip\")\n",
    "# else:\n",
    "#     print(f\"No profiles folder found at: {profiles_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c331104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ZIP: /content/GPU_mode/profiles_20251129_024917.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "repo_root = \"/content/GPU_mode\"\n",
    "profiles_dir = os.path.join(repo_root, \"profiles\")\n",
    "\n",
    "# Make timestamped name\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_basename = f\"profiles_{timestamp}\"             # without .zip\n",
    "zip_path = os.path.join(repo_root, zip_basename)   # /content/GPU_mode/profiles_YYYYMMDD_HHMMSS\n",
    "\n",
    "if os.path.isdir(profiles_dir):\n",
    "    # Create /content/GPU_mode/profiles_YYYYMMDD_HHMMSS.zip\n",
    "    shutil.make_archive(zip_path, \"zip\", profiles_dir)\n",
    "    zip_file = zip_path + \".zip\"\n",
    "    print(f\"Created ZIP: {zip_file}\")\n",
    "else:\n",
    "    print(f\"No profiles folder found at: {profiles_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18d3a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\t       profiles\t\t\t     test_colab_server.ipynb\n",
      "CMakeLists.txt\t       profiles_20251129_024917.zip  vector_add\n",
      "include\t\t       README.md\n",
      "matrix_multiplication  reduction\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1a8dbf",
   "metadata": {},
   "source": [
    "# File Downloader Widget/Workflow Provided by Colab For the Profiler Zip File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fa9706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anywidget\n",
    "import traitlets\n",
    "import os\n",
    "import base64\n",
    "import mimetypes\n",
    "\n",
    "class FileDownloader(anywidget.AnyWidget):\n",
    "    \"\"\"\n",
    "    An anywidget that renders a button. When clicked, it triggers a server-side\n",
    "    read of 'file_path' and sends the content to the browser for download.\n",
    "\n",
    "    The button starts disabled and only enables after a successful handshake\n",
    "    with the Python kernel, ensuring it doesn't appear active in a dead notebook.\n",
    "    \"\"\"\n",
    "\n",
    "    # The path to the file on the server/local disk that you want to download\n",
    "    file_path = traitlets.Unicode(help=\"Path to the file to be downloaded\").tag(sync=True)\n",
    "\n",
    "    # Label for the button\n",
    "    button_text = traitlets.Unicode(\"Download File\").tag(sync=True)\n",
    "\n",
    "    _esm = \"\"\"\n",
    "    export function render({ model, el }) {\n",
    "      // Create the button element\n",
    "      let btn = document.createElement(\"button\");\n",
    "      btn.classList.add(\"jupyter-widgets\", \"jupyter-button\", \"widget-button\");\n",
    "      btn.style.width = \"100%\";\n",
    "\n",
    "      // Initial state: Disabled and waiting\n",
    "      btn.innerText = \"Waiting for Kernel...\";\n",
    "      btn.disabled = true;\n",
    "\n",
    "      // Update button text if the Python trait changes\n",
    "      model.on(\"change:button_text\", () => {\n",
    "        // Only update visually if we are already connected/enabled\n",
    "        if (!btn.disabled) {\n",
    "            btn.innerText = model.get(\"button_text\");\n",
    "        }\n",
    "      });\n",
    "\n",
    "      // Handle the click event\n",
    "      btn.addEventListener(\"click\", () => {\n",
    "        const filePath = model.get(\"file_path\");\n",
    "\n",
    "        if (!filePath) {\n",
    "            alert(\"No file path set in the Python widget!\");\n",
    "            return;\n",
    "        }\n",
    "\n",
    "        // Disable button and show loading state\n",
    "        const originalText = btn.innerText;\n",
    "        btn.innerText = \"Downloading...\";\n",
    "        btn.disabled = true;\n",
    "\n",
    "        // Send a request message to the Python backend\n",
    "        model.send({ type: \"request_download\" });\n",
    "\n",
    "        // Helper to restore button state\n",
    "        const restoreBtn = () => {\n",
    "            btn.innerText = originalText;\n",
    "            btn.disabled = false;\n",
    "        };\n",
    "\n",
    "        // Timeout safety to restore button if Python doesn't respond within 5s\n",
    "        setTimeout(restoreBtn, 5000);\n",
    "      });\n",
    "\n",
    "      el.appendChild(btn);\n",
    "\n",
    "      // Listen for messages coming from Python\n",
    "      model.on(\"msg:custom\", (msg) => {\n",
    "        if (msg.type === \"connection_verified\") {\n",
    "            // HANDSHAKE COMPLETE: Kernel is alive.\n",
    "            btn.disabled = false;\n",
    "            btn.innerText = model.get(\"button_text\");\n",
    "        }\n",
    "        else if (msg.type === \"file_content\") {\n",
    "            // 1. Create a Blob from the Base64 data\n",
    "            const byteCharacters = atob(msg.content);\n",
    "            const byteNumbers = new Array(byteCharacters.length);\n",
    "            for (let i = 0; i < byteCharacters.length; i++) {\n",
    "                byteNumbers[i] = byteCharacters.charCodeAt(i);\n",
    "            }\n",
    "            const byteArray = new Uint8Array(byteNumbers);\n",
    "            const blob = new Blob([byteArray], { type: msg.mime_type });\n",
    "\n",
    "            // 2. Create a temporary link to trigger the download\n",
    "            const url = window.URL.createObjectURL(blob);\n",
    "            const a = document.createElement(\"a\");\n",
    "            a.style.display = \"none\";\n",
    "            a.href = url;\n",
    "            a.download = msg.filename;\n",
    "            document.body.appendChild(a);\n",
    "            a.click();\n",
    "\n",
    "            // 3. Cleanup\n",
    "            window.URL.revokeObjectURL(url);\n",
    "            document.body.removeChild(a);\n",
    "\n",
    "            // Restore button text\n",
    "            btn.innerText = model.get(\"button_text\");\n",
    "            btn.disabled = false;\n",
    "\n",
    "        } else if (msg.type === \"error\") {\n",
    "            alert(`Error: ${msg.message}`);\n",
    "            btn.innerText = model.get(\"button_text\");\n",
    "            btn.disabled = false;\n",
    "        }\n",
    "      });\n",
    "\n",
    "      // INITIATE HANDSHAKE\n",
    "      // Send a message to Python to check if the kernel is listening.\n",
    "      // If the kernel is dead (saved notebook), this message goes nowhere,\n",
    "      // and the button remains disabled.\n",
    "      setTimeout(() => {\n",
    "        model.send({ type: \"check_connection\" });\n",
    "      }, 500);\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_path=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if file_path:\n",
    "            self.file_path = file_path\n",
    "\n",
    "        # Register the message handler\n",
    "        self.on_msg(self._handle_custom_msg)\n",
    "\n",
    "    def _handle_custom_msg(self, msg, content):\n",
    "        \"\"\"\n",
    "        Callback for when the frontend sends a message to Python.\n",
    "        \"\"\"\n",
    "        msg_type = msg.get(\"type\")\n",
    "\n",
    "        if msg_type == \"check_connection\":\n",
    "            # Reply to the frontend to confirm we are alive\n",
    "            self.send({\"type\": \"connection_verified\"})\n",
    "\n",
    "        elif msg_type == \"request_download\":\n",
    "            self._process_download()\n",
    "\n",
    "    def _process_download(self):\n",
    "        \"\"\"\n",
    "        Reads the file from disk and sends it to the frontend.\n",
    "        \"\"\"\n",
    "        target_path = self.file_path\n",
    "\n",
    "        # Basic validation\n",
    "        if not target_path:\n",
    "            self.send({\"type\": \"error\", \"message\": \"File path is not defined.\"})\n",
    "            return\n",
    "\n",
    "        if not os.path.exists(target_path):\n",
    "            self.send({\"type\": \"error\", \"message\": f\"File not found: {target_path}\"})\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Guess the MIME type so the browser handles it correctly\n",
    "            mime_type, _ = mimetypes.guess_type(target_path)\n",
    "            if mime_type is None:\n",
    "                mime_type = 'application/octet-stream'\n",
    "\n",
    "            # Read and encode the file\n",
    "            with open(target_path, \"rb\") as f:\n",
    "                file_content = f.read()\n",
    "\n",
    "            b64_content = base64.b64encode(file_content).decode(\"utf-8\")\n",
    "\n",
    "            # Send back to JS\n",
    "            self.send({\n",
    "                \"type\": \"file_content\",\n",
    "                \"filename\": os.path.basename(target_path),\n",
    "                \"mime_type\": mime_type,\n",
    "                \"content\": b64_content\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            self.send({\"type\": \"error\", \"message\": str(e)})\n",
    "\n",
    "# dummy_filename = \"example_data.txt\"\n",
    "# with open(dummy_filename, \"w\") as f:\n",
    "#     f.write(\"Hello! This is a file dynamically read from the kernel disk.\\n\")\n",
    "#     f.write(\"If you are reading this, the widget worked.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e81de5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f62ebbec22543c3a543947741ec527b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "<__main__.FileDownloader object at 0x7ed20032bec0>"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the timestamped zip with FileDownloader\n",
    "FileDownloader(file_path=zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135d312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
